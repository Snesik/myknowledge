# Содержание:
<a id="sections"></a>

* [Задачи и алгоритмы машинного обучения](#Machine-learning-tasks-and-algorithms)
   * [Задачи машинного обучения](#machine-learning-tasks)  
     * [Что такое обучение с учителем?](#supervised-learning)  
     * [Что такое обучение без учителя?](#unsupervised-learning)  
     * [Что такое классификация?](#classification)  
     * [Зачем использовать отбор (или селекцию) признаков (Feature selection)?](#Feature-selection)  
     * [Основные метрики задач классификации](#classification-metrics)
     * [Что такое кластеризация?](#clustering)  
     * [Что такое понижение размерности?](#dimension-reduction)  
     * [Что такое смещение и дисперсия, и каковы их отношения в моделировании данных?](#bias-and-variance)  
  * [Алгоритмы машинного обучения](#machine-learning-algorithms)  
     * [Линейная регрессия](#linear-regression)  
     * [Логистическая регрессия](#logistic-regression)  
     * [Линейный дискриминантный анализ (LDA)](#LDA)
     * [Случайный лес (Random Forest)](#Random-Forest)
     * [Метод опорных векторов (SVM)](#SVM)
     * [K-ближайших соседей (KNN)](#KNN)
     * [Наивный Байесовский классификатор](#Bayes)
   * [Бустинг](#boosting)  
   * [Метрики регрессии](#Regression-metrics)
   * [Обучение с помощью градиентного спуска](#gradient-descent-training)
   * [Алгоритмы кластеризации такие как k-means и c-means, dbscan](#k-means-c-means-dbscan)
   * [Иерархическая кластеризация](#hierarchical-clustering)
   * [Алгоритмы понижения размерности такие как PCA, t-SNE](#lPCA-t-SNE)
   * [Что такое регуляризация и чем она полезна?](#regularization)
   * [Алгоритмы для нейронных сетей](#algorithms-for-neural-networksn)
   * [Полносвязная нейронная сеть](#fully-connected-neural-network)
   * [Свёрточная нейронная сеть](#convolutional-neural-networkn)
   * [Рекуррентная нейронная сеть](#recurrent-neural-network)
   * [Для каких задач подходит тот или иной алгоритм?](#algorithm-suitable)
   * [Что такое градиент и для чего он нужен?](#gradient)
   * [Что такое функция активации?](#activation-function)

* [Сеть](#network)
   * [Что такое веб-сервисы?](#web-services)
   * [REST](#rest)  
   * [http](#http)
   * [JSON](#json)   
   * [XML](#xml)
   * [Очереди сообщений](#message-queues)
   * [Что происходит в тот момент, когда вы вводите в адресной строке браузера URL сайта и нажимаете ввод?](#www)

* [Бизнес](#business)

* [Источники](#sources)
<br/>





# МатСтат и ТерВер
<a id="statistics-and-probability-theory"></a>
([наверх](#sections))

* [Меры центральной тенденции](#сentral-trend-measures)
* [Процентили и квартили](#percentile-and-quartile)
* [Математическое ожидание](#expected-value)
* [Меры изменчивости](#Measures-of-variability)

## Меры центральной тенденции
<a id="сentral-trend-measures"></a>

Используются, когда вам нужно отразить наиболее типичные значения, присутствующие в вашей
выборке.
Состав:
  1. Мода – наиболее часто встречающееся значение.
  2. Медиана – середина упорядоченного ряда значений.
  3. Среднее арифметическое – сумма значений, деленная на их количество.

Пример: определение наиболее типичной зарплаты в нашей стране можно осуществлять по двум показателям – среднему арифметическому и медиане. Первая определяется как количество денег, деленное на количество людей, а второе – как зарплата человека, стоящего ровно посередине между самым бедным и самым богатым. Как правило, эти значения различаются – средняя зарплата выше медианной. И чем это различие больше, тем выше социальное неравенство в обществе.

**Мода** — значение во множестве наблюдений, которое встречается наиболее часто. (Мода = типичность.) Иногда в совокупности встречается более чем одна мода (например: 6, 2, 6, 6, 8, 9, 9, 9, 0; мода — 6 и 9). В этом случае можно сказать, что совокупность мультимодальна. Из структурных средних величин только мода обладает таким уникальным свойством. Как правило, мультимодальность указывает на то, что набор данных не подчиняется нормальному распределению. Мода как средняя величина употребляется чаще для данных, имеющих нечисловую природу.

Для интервального ряда мода определяется по формуле:

![мода для интервального ряда](http://www.univer-nn.ru/statistics/moda.jpg)

здесь XMо — левая граница модального интервала, hМо — длина модального интервала, fМо − 1 — частота премодального интервала, fМо — частота модального интервала, fМо + 1 — частота послемодального интервала.

Модой абсолютно непрерывного распределения называют любую точку локального максимума плотности распределения. Для дискретных распределений модой считают любое значение ai, вероятность которого pi больше, чем вероятности соседних значений.

**Медиана** — это такое значение признака, которое разделяет ранжированный ряд распределения на две равные части — со значениями признака меньше медианы и со значениями признака больше медианы. Для нахождения медианы, нужно отыскать значение признака, которое находится на середине упорядоченного ряда.

В ранжированных рядах несгруппированные данные для нахождения медианы сводятся к поиску порядкового номера медианы. Медиана может быть вычислена по следующей формуле:

![медиана](http://www.univer-nn.ru/statistics/mediana.jpg)

где Хm — нижняя граница медианного интервала;  
im — медианный интервал;  
Sme— сумма наблюдений, которая была накоплена до начала медианного интервала;  
fme — число наблюдений в медианном интервале.  

* Медиана не зависит от тех значений признака, которые расположены по обе стороны от нее.  
* Аналитические операции с медианой весьма ограничены, поэтому при объединении двух распределений с известными медианами невозможно заранее предсказать величину медианы нового распределения.  
* Медиана обладает свойством минимальности. Его суть заключается в том, что сумма абсолютных отклонений значений х, от медианы представляет собой минимальную величину по сравнению с отклонением X от любой другой величины

**Среднее арифметическое** — такое среднее значение признака, при вычислении которого общий объем признака в совокупности сохраняется неизменным. Для того чтобы вычислить среднюю арифметическую, необходимо сумму всех значений признаков разделить на их число.

Оно применяется в тех случаях, когда объем варьирующего признака для всей совокупности является суммой значений признаков отдельных ее единиц. 

Среднее арифметическое может быть вычислена по формуле:

![ср.ар](http://www.univer-nn.ru/statistics/arifmet-simple.jpg)

где n — численность совокупности.  

Средняя арифметическая взвешенная — это средняя из вариантов, которые повторяются разное число раз или имеют различный вес. Она может быть рассчитана по формуле:

![ср.ар.взв](http://www.univer-nn.ru/statistics/arifmet-vzvesh.jpg)

## Процентили и квартили
<a id="percentile-and-quartile"></a>
([наверх](#sections))

Квантииль в математической статистике — значение, которое заданная случайная величина не превышает с фиксированной вероятностью. Если вероятность задана в процентах, то квантиль называется процентилем или перцентилем 

**Процентиль** — мера, в которой процентное значение общих значений равно этой мере или меньше ее. Например, 90 % значений данных находятся ниже 90-го процентиля, а 10 % значений данных находятся ниже 10-го процентиля.

**Квартили** — значения, которые делят таблицу данных (или ее часть) на четыре группы, содержащие приблизительно равное количество наблюдений. Общий объем делится на четыре равные части: 25%, 50%, 75% 100%.

* 0,25-квантиль называется первым (или нижним) кварти́лем (от лат. quarta — четверть);
* 0,5-квантиль называется медианой (от лат. mediāna — середина) или вторым кварти́лем;
* 0,75-квантиль называется третьим (или верхним) кварти́лем.

Процентиль можно пояснить и на примере симметричного распределения Гаусса, которое часто встречается в статистике для оценки веса, роста и т.п. 

![ImageGauss](https://investprofit.info/wp-content/uploads/2020/06/ImageGauss.gif)

На рисунке выше показаны 25, 50, 75 и 100 процентили. Случаи 25 и 75-ого процентиля, включающие четверть и три четверти выборки соответственно, называются квартилями.

Интеркварти́льным размахом (англ. Interquartile range) называется разность между третьим и первым квартилями, то есть ![f-la](https://wikimedia.org/api/rest_v1/media/math/render/svg/99e771cbcd10f208efd9cabd46f266a29a21c49e). Интерквартильный размах является характеристикой разброса распределения величины и является робастным аналогом дисперсии. Вместе, медиана и интерквартильный размах могут быть использованы вместо математического ожидания и дисперсии в случае распределений с большими выбросами, либо при невозможности вычисления последних.

**Дециль** характеризует распределение величин совокупности, при котором девять значений дециля делят её на десять равных частей. Любая из этих десяти частей составляет 1/10 всей совокупности. Так, первый дециль отделяет 10 % наименьших величин, лежащих ниже дециля, от 90 % наибольших величин, лежащих выше дециля.

Так же, как в случае моды и медианы, у интервального вариационного ряда распределения каждый дециль (и квартиль) принадлежит определённому интервалу и имеет вполне определённое значение.

## Математическое ожидание
<a id="expected-value"></a>
([наверх](#sections))

Математическое ожидание — означает среднее (взвешенное по вероятностям возможных значений) значение случайной величины. В случае непрерывной случайной величины подразумевается взвешивание по плотности распределения. Математическое ожидание случайного вектора равно вектору, компоненты которого равны математическим ожиданиям компонентов случайного вектора.

Математическое ожидание – это сумма произведений всех возможных значений случайной величины на вероятности этих значений.

Обозначается через ![матож1](https://wikimedia.org/api/rest_v1/media/math/render/svg/09de7acbba84104ff260708b6e9b8bae32c3fafa) в русскоязычной литературе также встречается обозначение ![матож2](https://wikimedia.org/api/rest_v1/media/math/render/svg/87b00856eb008c4ea9bc42894bb2bfa0b8605ac2). В статистике часто используют обозначение ![mu](https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161).

Для случайной величины, принимающей значения только 0 или 1 математическое ожидание равно p — вероятности «единицы». Математическое ожидание суммы таких случайных величин равно np, где n — количество таких случайных величин. При этом вероятности появления определенного кол-ва единиц рассчитываются по биномиальному распределению. Некоторые случайные величины не имеют математического ожидания, например, случайные величины, имеющие распределение Коши.

На практике математическое ожидание обычно оценивается как среднее арифметическое наблюдаемых значений случайной величины (выборочное среднее, среднее по выборке). 

## Меры изменчивости
<a id="Measures-of-variability"></a>
([наверх](#sections))

Используются, когда нужно отразить степень разброса значений относительно меры центральной
тенденции.
Состав:
  1. Размах – разность между максимальным и минимальным значениями.
  2. Дисперсия – сумма квадратов отклонений, деленная на их количество. Отклонение – это разность между средним арифметическим и конкретным значением. Дисперсии для генеральной совокупности и для выборки вычисляются по разным формулам.
  3. Стандартное отклонение – корень из дисперсии.

**Размах** — разность между наибольшим и наименьшим значениями результатов наблюдений. Пусть ![f-la3](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac794f5521dcce89913085a6d566e7cdb615dbb0) — взаимно независимые случайные величины с функцией распределения F(x) и плотностью вероятности f(x). В этом случае размах Wn определяется как разность между наибольшим и наименьшим значениями среди ![f-la3](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac794f5521dcce89913085a6d566e7cdb615dbb0); размах Wn представляет собой случайную величину, которой соответствует функция распределения:

![Размах](https://wikimedia.org/api/rest_v1/media/math/render/svg/4830e22fab4992a6f37ebc9423dc892b419bc08d)

(при w >= 0; если w < 0, то P {W <= w} = 0).
В математической статистике размах, надлежащим образом нормированный, применяется как оценка неизвестного квадратичного отклонения. Например, если Xk имеют нормальное распределение с параметрами (а, s), то при n = 5 и 10, соответственно, величины 0,4299W5 и 0,3249W10 будут несмещенными оценками s. Такие оценки часто используют при статистическом контроле качества, поскольку определение Р. нескольких результатов измерений не требует сложных вычислений.

**Дисперсией** случайной величины называют математическое ожидание квадрата отклонения случайной величины от её математического ожидания.

Пусть X — случайная величина, определённая на некотором вероятностном пространстве. Тогда дисперсией называется

![Дисперсия](https://wikimedia.org/api/rest_v1/media/math/render/svg/59b03d2df3d9b588fcda27ed5489de5541d56844)
где символ M обозначает математическое ожидание

# Задачи и алгоритмы машинного обучения
<a id="Machine-learning-tasks-and-algorithms"></a>

* [Задачи машинного обучения](#machine-learning-tasks)  
  * [Что такое обучение с учителем?](#supervised-learning)  
  * [Что такое обучение без учителя?](#unsupervised-learning)  
  * [Что такое классификация?](#classification)  
  * [Зачем использовать отбор (или селекцию) признаков (Feature selection)?](#Feature-selection)  
  * [Основные метрики задач классификации](#classification-metrics)
  * [Что такое кластеризация?](#clustering)  
  * [Что такое понижение размерности?](#dimension-reduction)  
  * [Что такое смещение и дисперсия, и каковы их отношения в моделировании данных?](#bias-and-variance)  
* [Алгоритмы машинного обучения](#machine-learning-algorithms)  
    * [Линейная регрессия](#linear-regression)  
    * [Логистическая регрессия](#logistic-regression)  
    * [Линейный дискриминантный анализ (LDA)](#LDA)
    * [Случайный лес (Random Forest)](#Random-Forest)
    * [Метод опорных векторов (SVM)](#SVM)
    * [K-ближайших соседей (KNN)](#KNN)
    * [Наивный Байесовский классификатор](#Bayes)
* [Бустинг](#boosting)  
* [Метрики регрессии](#Regression-metrics)
* [Обучение с помощью градиентного спуска](#gradient-descent-training)
* [Алгоритмы кластеризации такие как k-means и c-means, dbscan](#k-means-c-means-dbscan)
* [Иерархическая кластеризация](#hierarchical-clustering)
* [Алгоритмы понижения размерности такие как PCA, t-SNE](#lPCA-t-SNE)
* [Что такое регуляризация и чем она полезна?](#regularization)
* [Алгоритмы для нейронных сетей](#algorithms-for-neural-networksn)
* [Полносвязная нейронная сеть](#fully-connected-neural-network)
* [Свёрточная нейронная сеть](#convolutional-neural-networkn)
* [Рекуррентная нейронная сеть](#recurrent-neural-network)
* [Для каких задач подходит тот или иной алгоритм?](#algorithm-suitable)
* [Что такое градиент и для чего он нужен?](#gradient)
* [Что такое функция активации?](#activation-function)

([наверх](#sections))

## Задачи машинного обучения
<a id="machine-learning-tasks"></a>

### Что такое обучение с учителем?
<a id="supervised-learning"></a>
([наверх](#sections))

В данном случае в тренировочном датасете для кажого объекта у нас есть метка или лэйбл. В тестовом - этого лейбла нет и нам нужно его предсказать. 
Бывает два подтипа решения задач с учителем:

* Регрессия

В задачах регрессии меткой является вещественное число.  

Например, если мы предсказываем стоимость квартиры, то это будет задача регрессии.

* Классификация

В данном случае мы предсказываем не вещественное число, а конечно подмножество классов.  
Если таких классов два, то это задача бинарной классификации.
Если больше двух, то это многоклассовая классификация.  

Например, если мы предсказываем есть на фотографии машина или нет, то это задача бинарной классификации, потому-что у нас в данном случае два класса (либо машина есть, либо её нет)

### Что такое обучение без учителя?
<a id="unsupervised-learning"></a>
([наверх](#sections))

В данном случае у нас нет лейблов для объектов, и мы не пытаемся их предсказать.  
Бывает несколько подтипов решения задач без учителя:

* Кластеризация

В данном случае попытаемся выявить некоторые паттерны в данных и объединить их в кластеры. Так, чтобы в одном кластере были похожие объекты, а в разных кластерах они были разные.  

Например, мы хотим разбить фильмы по жанрам и мы не знаем какие у нас жанры есть, мы хотим понять чем они отличаются друг от друга и на какое количество кластеров их хорошо разбить.

* Задача понижения размерности  

В данном случае мы хотим вектора большой размерности ужать до меньшей, при этом сохранить как можно больше информации

* Визуализация

Уменьшаем размерность до состояния, когда её можно визуализировать

### Что такое классификация?
<a id="classification"></a>
([наверх](#sections))

Классификация — один из разделов машинного обучения, посвященный решению следующей задачи. Имеется множество объектов (ситуаций), разделённых некоторым образом на классы. Задано конечное множество объектов, для которых известно, к каким классам они относятся. Это множество называется обучающей выборкой. Классовая принадлежность остальных объектов не известна. Требуется построить алгоритм, способный классифицировать произвольный объект из исходного множества.  

Классифицировать объект — значит, указать номер (или наименование класса), к которому относится данный объект.  

Классификация объекта — номер или наименование класса, выдаваемый алгоритмом классификации в результате его применения к данному конкретному объекту.  

В математической статистике задачи классификации называются также задачами дискриминантного анализа.

В машинном обучении задача классификации относится к разделу обучения с учителем. Существует также обучение без учителя, когда разделение объектов обучающей выборки на классы не задаётся, и требуется классифицировать объекты только на основе их сходства друг с другом. В этом случае принято говорить о задачах кластеризации или таксономии, и классы называть, соответственно, кластерами или таксонами.

**Типология задач классификации**  
_Типы входных данных_
* Признаковое описание — наиболее распространённый случай. Каждый объект описывается набором своих характеристик, называемых признаками. Признаки могут быть числовыми или нечисловыми.  
* Матрица расстояний между объектами. Каждый объект описывается расстояниями до всех остальных объектов обучающей выборки. С этим типом входных данных работают немногие методы, в частности, метод ближайших соседей, метод парзеновского окна, метод потенциальных функций.  
* Временной ряд или сигнал представляет собой последовательность измерений во времени. Каждое измерение может представляться числом, вектором, а в общем случае — признаковым описанием исследуемого объекта в данный момент времени.  
* Изображение или видеоряд.  
* Встречаются и более сложные случаи, когда входные данные представляются в виде графов, текстов, результатов запросов к базе данных, и т. д. Как правило, они приводятся к первому или второму случаю путём предварительной обработки данных и извлечения признаков.  
Классификацию сигналов и изображений называют также распознаванием образов.

_Типы классов_
* Двухклассовая классификация. Наиболее простой в техническом отношении случай, который служит основой для решения более сложных задач.  
* Многоклассовая классификация. Когда число классов достигает многих тысяч (например, при распознавании иероглифов или слитной речи), задача классификации становится существенно более трудной.  
* Непересекающиеся классы.  
* Пересекающиеся классы. Объект может относиться одновременно к нескольким классам.  
* Нечёткие классы. Требуется определять степень принадлежности объекта каждому из классов, обычно это действительное число от 0 до 1.  

### Зачем использовать отбор (или селекцию) признаков (Feature selection)?
<a id="Feature-selection"></a>
([наверх](#sections))

Отбор признаков используют для устранения избыточных признаков (например, которые дублируются) и нерелевантных (например, которые не имеют отношения к решению задачи) признаков, что может

* повысить надёжность обучения (уменьшить эффект переобучения),
* улучшить интерпретируемость решения (модель будет зависеть от небольшого числа признаков),
* упростить поддержку решения (чем меньше входных данных, тем проще понять, из-за каких изменений входа алгоритм стал себя неадекватно вести),
* повысить скорость работы алгоритмов (чем меньше признаков, тем быстрее),
* удешевить решение задачи (часто получение признаков связано с денежными затратами — установка дополнительных датчиков, запросы нужной информации и т.п., здесь мы получаем возможность узнать, что чаcть признаков можно не использовать).

### Основные метрики задач классификации
<a id="classification-metrics"></a>
([наверх](#sections))

Рассматриваемые нами метрики основаны на использовании следующих исходов: истинно положительные (TP), истинно отрицательные (TN), ложно положительные (FP) и ложно отрицательные (FN)

![Performance-measurement](https://www.researchgate.net/profile/Nimmisha-Shajihan/publication/347447352/figure/fig3/AS:970048604741634@1608289018974/Performance-measurement-TP-TN-FP-FN-are-the-parameters-used-in-the-evaluation-of.jpg)

**Accuracy**


Одной из наиболее простых, а поэтому и распространенной метрикой является точность. Она показывает количество правильно проставленных меток класса (истинно положительных и истинно отрицательных) от общего количества данных и считается следующим образом

![Accuracy](https://webiomed.ai/media/ck_uploads/2020/07/08/bezimeni-3_VdaeGz8.png)

Однако, эта простота является также и причиной, почему её часто критикуют и почему она может абсолютно не подойти под решаемую задачу. Она не учитывает соотношения ложных срабатываний модели, что может быть критическим, особенно в медицинской сфере, когда стоит задача распознать все истинные случаи диагноза.

**Precision**

Эта точность показывает количество истинно положительных исходов из всего набора положительных меток и считается по следующей формуле

![Precision](https://webiomed.ai/media/ck_uploads/2020/07/08/bezimeni-4.png)

Важность этой метрики определяется тем, насколько высока для рассматриваемой задачи «цена» ложно положительного результата. Если, например, стоимость дальнейшей проверки наличия заболевания у пациента высока и мы просто не можем проверить все ложно положительные результаты, то стоит максимизировать данную метрику, ведь при Precision = 50% из 100 положительно определенных больных  диагноз будут иметь лишь 50 из них.

**Recall (true positive rate)**

«полнота» или «чувствительность». Эта метрика определяет количество истинно положительных среди всех меток класса, которые были определены как «положительный» и вычисляется по следующей формуле

![Recall](https://webiomed.ai/media/ck_uploads/2020/07/08/bezimeni-5.png)

Необходимо уделить особое внимание этой оценке, когда в поставленной задаче ошибка нераспознания положительного класса высока.

**F1-Score**

В том случае, если Precision и Recall являются одинаково значимыми, можно использовать их среднее гармоническое для получения оценки результатов

![F1-Score](https://webiomed.ai/media/ck_uploads/2020/07/08/bezimeni-9.png)

**ROC**

ROC (receiver operating characteristic) – график, показывающий зависимость верно классифицируемых объектов положительного класса от ложно положительно классифицируемых объектов негативного класса. Иными словами, соотношение True Positive Rate (Recall) и False Positive Rate. 

![roc](https://webiomed.ai/media/ck_uploads/2020/07/08/2.png)

Идеальное значение графика находится в верхней левой точке (TPR = 1, a FPR = 0). При этом, кривая, соответствующая FPR = TPR является случайным гаданием, а если график кривой модели или точка находятся ниже этого минимума, то это говорит лишь о том, что лучше подбрасывать монетку, чем использовать эту модель. При этом говорят, что кривая X доминирует над другой кривой Y, если X в любом точке находится левее и выше Y, что означает превосходство первого классификатора над вторым.

С помощью ROC — кривой, можно сравнить модели, а также их параметры для поиска наиболее оптимальной (с точки зрения tpr и fpr) комбинации. В этом случае ищется компромисс между количеством больных, метка которых была правильно определена как положительная и количеством больных, метка которых была неправильно определена как положительная.

**AUC (Area Under Curve)**

В качестве численной оценки ROC кривой принято брать площадь под этой кривой, которая является неплохим «итогом» для кривой. Если между кривыми X и Y существует доминирование первой над второй, то AUC (X) > AUC (Y), обратное не всегда верно. Но AUC обладает так же и статистическим смыслом: она показывает вероятность того, что случайно выбранный экземпляр негативного класса будет иметь меньше вероятность быть распознанным как позитивный класс, чем случайно выбранный позитивный класс.

**Мульти-классификация**

Одним из возможных способов обобщения метрик является вычисление среднего метрики по всем классам. Тогда в качестве «положительного» класса берется вычисляемый, а все остальные — в качестве «отрицательного».

В этом случае формулы для метрик будут выглядеть следующим образом:

![Мульти-классификация](https://webiomed.ai/media/ck_uploads/2020/07/08/bezimeni-8.png)

### Что такое кластеризация?
<a id="clustering"></a>
([наверх](#sections))

Кластерный анализ (Data clustering) — задача разбиения заданной выборки объектов (ситуаций) на непересекающиеся подмножества, называемые кластерами, так, чтобы каждый кластер состоял из схожих объектов, а объекты разных кластеров существенно отличались.

Задача кластеризации относится к широкому классу задач обучения без учителя.

**Типология задач кластеризации**

*Типы входных данных*  
Признаковое описание объектов. Каждый объект описывается набором своих характеристик, называемых признаками. Признаки могут быть числовыми или нечисловыми.
Матрица расстояний между объектами. Каждый объект описывается расстояниями до всех остальных объектов обучающей выборки.
Матрица расстояний может быть вычислена по матрице признаковых описаний объектов бесконечным числом способов, в зависимости от того, как ввести функцию расстояния (метрику) между признаковыми описаниями. Часто используется евклидова метрика, однако этот выбор в большинстве случаев является эвристикой и обусловлен лишь соображениями удобства.

Обратная задача — восстановление признаковых описаний по матрице попарных расстояний между объектами — в общем случае не имеет решения, а приближённое решение не единственно и может иметь существенную погрешность. Эта задача решается методами многомерного шкалирования.

Таким образом, постановка задачи кластеризации по матрице расстояний является более общей. С другой стороны, при наличии признаковых описаний часто удаётся строить более эффективные методы кластеризации.

*Цели кластеризации*  
Понимание данных путём выявления кластерной структуры. Разбиение выборки на группы схожих объектов позволяет упростить дальнейшую обработку данных и принятия решений, применяя к каждому кластеру свой метод анализа (стратегия «разделяй и властвуй»).
Сжатие данных. Если исходная выборка избыточно большая, то можно сократить её, оставив по одному наиболее типичному представителю от каждого кластера.
Обнаружение новизны (novelty detection). Выделяются нетипичные объекты, которые не удаётся присоединить ни к одному из кластеров.
В первом случае число кластеров стараются сделать поменьше. Во втором случае важнее обеспечить высокую (или фиксированную) степень сходства объектов внутри каждого кластера, а кластеров может быть сколько угодно. В третьем случае наибольший интерес представляют отдельные объекты, не вписывающиеся ни в один из кластеров.

Во всех этих случаях может применяться иерархическая кластеризация, когда крупные кластеры дробятся на более мелкие, те в свою очередь дробятся ещё мельче, и т. д. Такие задачи называются задачами таксономии.

Результатом таксономии является древообразная иерархическая структура. При этом каждый объект характеризуется перечислением всех кластеров, которым он принадлежит, обычно от крупного к мелкому. Визуально таксономия представляется в виде графика, называемого дендрограммой.

Классическим примером таксономии на основе сходства является биноминальная номенклатура живых существ, предложенная Карлом Линнеем в середине XVIII века. Аналогичные систематизации строятся во многих областях знания, чтобы упорядочить информацию о большом количестве объектов.

*Функции расстояния*
* Метрика Хэмминга
* Евклидова метрика
* Взвешенная евклидова метрика
* Метрика Минковского
*Методы кластеризации*
* Графовые алгоритмы кластеризации
* Статистические алгоритмы кластеризации
    * Алгоритм k-средних (k-means)
    * EM-алгоритм
* Алгоритм ФОРЕЛЬ
* Иерархическая кластеризация или таксономия
* Нейронная сеть Кохонена
* Ансамбль кластеризаторов

**Формальная постановка задачи кластеризации**

Пусть X  — множество объектов, Y — множество номеров (имён, меток) кластеров. Задана функция расстояния между объектами ![\rho(x,x')](https://latex.codecogs.com/png.image?\dpi{110}%20\rho(x,x%27)). Имеется конечная обучающая выборка объектов ![X^m = \{ x_1, \dots, x_m \} \subset X](https://latex.codecogs.com/png.image?\dpi{110}%20X^m%20=%20\{%20x_1,%20\dots,%20x_m%20\}%20\subset%20X). Требуется разбить выборку на непересекающиеся подмножества, называемые кластерами, так, чтобы каждый кластер состоял из объектов, близких по метрике p, а объекты разных кластеров существенно отличались. При этом каждому объекту ![x_i\in X^m](https://latex.codecogs.com/png.image?\dpi{110}%20x_i\in%20X^m) приписывается номер кластера ![y_i](https://latex.codecogs.com/png.image?\dpi{110}%20y_i).

Алгоритм кластеризации — это функция ![a:\, X\to Y](https://latex.codecogs.com/png.image?\dpi{110}%20a:\,%20X\to%20Y), которая любому объекту ![x\in X](https://latex.codecogs.com/png.image?\dpi{110}%20x\in%20X) ставит в соответствие номер кластера ![y\in Y](https://latex.codecogs.com/png.image?\dpi{110}%20y\in%20X). Множество Y в некоторых случаях известно заранее, однако чаще ставится задача определить оптимальное число кластеров, с точки зрения того или иного критерия качества кластеризации.

Кластеризация (обучение без учителя) отличается от классификации (обучения с учителем) тем, что метки исходных объектов ![y_i](https://latex.codecogs.com/png.image?\dpi{110}%20y_i) изначально не заданы, и даже может быть неизвестно само множество Y.

Решение задачи кластеризации принципиально неоднозначно, и тому есть несколько причин:

Не существует однозначно наилучшего критерия качества кластеризации. Известен целый ряд эвристических критериев, а также ряд алгоритмов, не имеющих чётко выраженного критерия, но осуществляющих достаточно разумную кластеризацию «по построению». Все они могут давать разные результаты.
Число кластеров, как правило, неизвестно заранее и устанавливается в соответствии с некоторым субъективным критерием.
Результат кластеризации существенно зависит от метрики, выбор которой, как правило, также субъективен и определяется экспертом.

### Что такое понижение размерности?
<a id="dimension-reduction"></a>
([наверх](#sections))

Под уменьшением размерности (англ. dimensionality reduction) в машинном обучении подразумевается уменьшение числа признаков набора данных. Наличие в нем признаков избыточных, неинформативных или слабо информативных может понизить эффективность модели, а после такого преобразования она упрощается, и соответственно уменьшается размер набора данных в памяти и ускоряется работа алгоритмов ML на нем. Уменьшение размерности может быть осуществлено методами выбора признаков (англ. feature selection) или выделения признаков 

### Что такое смещение и дисперсия, и каковы их отношения в моделировании данных?
<a id="bias-and-variance"></a>
([наверх](#sections))

Модель с большим смещением будет производить одинаковые ошибки для входа, независимо от обучающего множества, на котором происходило обучение. Модель смещает свои собственные предположения о реальных отношениях из-за связей, имеющихся в обучающих данных.

Модель с большой дисперсией, наоборот, будет производить различные ошибки для входа в зависимости от обучающего множества, на котором она училась.

Модель с большим смещением не гибкая, а модель с высокой дисперсией может быть, напротив, настолько гибкой, что смоделирует шум в обучающем множестве. То есть, модель с высокой дисперсией «переподгоняет» (overfit) обучающие данные, в то время как модель с большим смещением недостаточно точно подгоняет обучающие данные.

![Смещение и дисперсия](http://robotosha.ru/wp-content/uploads/2015/04/ml_bias_variance.png)

## Алгоритмы машинного обучения
<a id="machine-learning-algorithms"></a>
([наверх](#sections))

Алгоритмы машинного обучения можно описать как обучение целевой функции f, которая наилучшим образом соотносит входные переменные X и выходную переменную Y: Y = f(X).

Мы не знаем, что из себя представляет функция f. Ведь если бы знали, то использовали бы её напрямую, а не пытались обучить с помощью различных алгоритмов.

Наиболее распространённой задачей в машинном обучении является предсказание значений Y для новых значений X. Это называется прогностическим моделированием, и наша цель — сделать как можно более точное предсказание.

### Линейная регрессия
<a id="linear-regression"></a>
([наверх](#sections))

Алгоритм для задачи регрессии. Он предсказывает вещественное число, позволяет описывать линейную или биномиальную зависимость.  
Обучение происходит с помощью минимизации функции потерь, может быть две функции потерь.

Линейную регрессию можно представить в виде уравнения, которое описывает прямую, наиболее точно показывающую взаимосвязь между входными переменными X и выходными переменными Y. Для составления этого уравнения нужно найти определённые коэффициенты B для входных переменных.

![Линейная регрессия](https://tproger.ru/s3/uploads/2018/04/pic1.jpeg)

Средняя квадратичная ошибка:  

<img src="https://render.githubusercontent.com/render/math?math=MSE = \Sigma_{i=1}^{n}(y_i - y_i^p)^2">

Средняя абсолютная ошибка:  

<img src="https://render.githubusercontent.com/render/math?math=MAE = \Sigma_{i=1}^{n} \left| y_i - y_i^p \right |">

Обучение происходит с помощью градиентного спуска, также возможно аналитическое решение этой задачи с помощью нахождения обратной матрицы. Но в реальносnи оно не применятся, так как требует значительных вычислительных ресурсов, а также не для всех матриц можно найти обратную.

### Логистическая регрессия
<a id="logistic-regression"></a>
([наверх](#sections))

Это алгоритм для задачи классификации. Отличается от линейной регресси тем, что тут есть функция активации. 
Логистическая регрессия похожа на линейную тем, что в ней тоже требуется найти значения коэффициентов для входных переменных. Разница заключается в том, что выходное значение преобразуется с помощью нелинейной или логистической функции.

![Логистическая функция](https://tproger.ru/s3/uploads/2018/04/5vpYa.png)

Благодаря тому, как обучается модель, предсказания логистической регрессии можно использовать для отображения вероятности принадлежности образца к классу 0 или 1. Это полезно в тех случаях, когда нужно иметь больше обоснований для прогнозирования.

Для задач бинарной классификации используется сигмоида.  
Для задач многоклассовой классификации используется функция Softmax:  

<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ab3ef6ba51afd36c1d2baf06540022053b2dca73">

Функции потерь тоже отличаются:  
Для задач бинарной классификации - это LogLoss:  

<img src="https://alexanderdyakonov.files.wordpress.com/2018/03/log_loss_23.png">  

Для задач многоклассовой классификации - это categorical cross entropy

### Линейный дискриминантный анализ (LDA)
<a id="LDA"></a>
([наверх](#sections))

Логистическая регрессия используется, когда нужно отнести образец к одному из двух классов. Если классов больше, чем два, то лучше использовать алгоритм LDA (Linear discriminant analysis).

Представление LDA довольно простое. Оно состоит из статистических свойств данных, рассчитанных для каждого класса. Для каждой входной переменной это включает:

* Среднее значение для каждого класса;
* [Дисперсию](#Measures-of-variability), рассчитанную по всем классам.

Предсказания производятся путём вычисления дискриминантного значения для каждого класса и выбора класса с наибольшим значением. Предполагается, что данные имеют нормальное распределение, поэтому перед началом работы рекомендуется удалить из данных аномальные значения. Это простой и эффективный алгоритм для задач классификации.

### Случайный лес (Random Forest)
<a id="Random-Forest"></a>
([наверх](#sections))

RF (random forest) — это множество решающих деревьев. В задаче регрессии их ответы усредняются, в задаче классификации принимается решение голосованием по большинству. Все деревья строятся независимо по следующей схеме:

* Выбирается подвыборка обучающей выборки размера samplesize (м.б. с возвращением) – по ней строится дерево (для каждого дерева — своя подвыборка).
* Для построения каждого расщепления в дереве просматриваем max_features случайных признаков (для каждого нового расщепления — свои случайные признаки).
* Выбираем наилучшие признак и расщепление по нему (по заранее заданному критерию). Дерево строится, как правило, до исчерпания выборки (пока в листьях не останутся представители только одного класса), но в современных реализациях есть параметры, которые ограничивают высоту дерева, число объектов в листьях и число объектов в подвыборке, при котором проводится расщепление.

В библиотеке scikit-learn есть такая реализация RF (пример только для задачи классификации):

```
class sklearn.ensemble.RandomForestClassifier(n_estimators=10,
criterion='gini', max_depth=None, min_samples_split=2,
min_samples_leaf=1, min_weight_fraction_leaf=0.0,
max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07,
bootstrap=True, oob_score=False, n_jobs=1,
random_state=None, verbose=0, warm_start=False,
class_weight=None)
```
С алгоритмом работают по стандартной схеме, принятой в scikit-learn:

```
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import roc_auc_score
# далее - (X, y) - обучение, (X2, y2) - контроль
# модель - здесь (для контраста) рассмотрим регрессор
model =  RandomForestRegressor(n_estimators=10 ,
                               oob_score=True,
                               random_state=1)
model.fit(X, y) # обучение
a = model.predict(X2) # предсказание

print ("AUC-ROC (oob) = ", roc_auc_score(y, model.oob_prediction_))
print ("AUC-ROC (test) = ", roc_auc_score(y2, a))
```

**Число деревьев — n_estimators**  
Чем больше деревьев, тем лучше качество, но время настройки и работы RF также пропорционально увеличиваются. Обратите внимание, что часто при увеличении n_estimators качество на обучающей выборке повышается (может даже доходить до 100%), а качество на тесте выходит на асимптоту (можно прикинуть, скольких деревьев Вам достаточно).

![n_estimators](https://alexanderdyakonov.files.wordpress.com/2016/11/n_estimators.png?w=700)

**Число признаков для выбора расщепления — max_features**  
График качества на тесте от значения этого праметра унимодальный, на обучении он строго возрастает. При увеличении max_features увеличивается время построения леса, а деревья становятся «более однообразными». По умолчанию он равен sqrt(n) в задачах классификации и n/3 в задачах регрессии. Это самый важный параметр! Его настраивают в первую очередь (при достаточном числе деревьев в лесе).  

![max_features](https://alexanderdyakonov.files.wordpress.com/2016/11/max_features.png?w=700)

**Максимальная глубина деревьев — max_depth**  
Ясно, что чем меньше глубина, тем быстрее строится и работает RF. При увеличении глубины резко возрастает качество на обучении, но и на контроле оно, как правило, увеличивается. Рекомендуется использовать максимальную глубину (кроме случаев, когда объектов слишком много и получаются очень глубокие деревья, построение которых занимает значительное время). При использовании неглубоких деревьев изменение параметров, связанных с ограничением числа объектов в листе и для деления, не приводит к значимому эффекту (листья и так получаются «большими»). Неглубокие деревья рекомендуют использовать в задачах с большим числом шумовых объектов (выбросов).

![max_depth](https://alexanderdyakonov.files.wordpress.com/2016/11/max_depth.png?w=700)

### Метод опорных векторов (SVM)
<a id="SVM"></a>
([наверх](#sections))

Гиперплоскость — это линия, разделяющая пространство входных переменных. В методе опорных векторов гиперплоскость выбирается так, чтобы наилучшим образом разделять точки в плоскости входных переменных по их классу: 0 или 1. В двумерной плоскости это можно представить как линию, которая полностью разделяет точки всех классов. Во время обучения алгоритм ищет коэффициенты, которые помогают лучше разделять классы гиперплоскостью.

![SVM](https://tproger.ru/s3/uploads/2018/04/8.jpeg)

Расстояние между гиперплоскостью и ближайшими точками данных называется разницей. Лучшая или оптимальная гиперплоскость, разделяющая два класса, — это линия с наибольшей разницей. Только эти точки имеют значение при определении гиперплоскости и при построении классификатора. Эти точки называются опорными векторами. Для определения значений коэффициентов, максимизирующих разницу, используются специальные алгоритмы оптимизации.

Метод опорных векторов, наверное, один из самых эффективных классических классификаторов, на который определённо стоит обратить внимание.

### K-ближайших соседей (KNN)
<a id="KNN"></a>
([наверх](#sections))

К-ближайших соседей — очень простой и очень эффективный алгоритм. Модель KNN (K-nearest neighbors) представлена всем набором тренировочных данных. 

Предсказание для новой точки делается путём поиска K ближайших соседей в наборе данных и суммирования выходной переменной для этих K экземпляров.

Вопрос лишь в том, как определить сходство между экземплярами данных. Если все признаки имеют один и тот же масштаб (например, сантиметры), то самый простой способ заключается в использовании евклидова расстояния — числа, которое можно рассчитать на основе различий с каждой входной переменной.

KNN может потребовать много памяти для хранения всех данных, но зато быстро сделает предсказание. Также обучающие данные можно обновлять, чтобы предсказания оставались точными с течением времени.

Идея ближайших соседей может плохо работать с многомерными данными (множество входных переменных), что негативно скажется на эффективности алгоритма при решении задачи. Это называется проклятием размерности. Иными словами, стоит использовать лишь наиболее важные для предсказания переменные.

### Наивный Байесовский классификатор
<a id="Bayes"></a>
([наверх](#sections))

Наивный Байес — простой, но удивительно эффективный алгоритм.

Модель состоит из двух типов вероятностей, которые рассчитываются с помощью тренировочных данных:

Вероятность каждого класса.
Условная вероятность для каждого класса при каждом значении x.
После расчёта вероятностной модели её можно использовать для предсказания с новыми данными при помощи теоремы Байеса. Если у вас вещественные данные, то, предполагая нормальное распределение, рассчитать эти вероятности не составляет особой сложности.

Наивный Байес называется наивным, потому что алгоритм предполагает, что каждая входная переменная независимая. Это сильное предположение, которое не соответствует реальным данным. Тем не менее данный алгоритм весьма эффективен для целого ряда сложных задач вроде классификации спама или распознавания рукописных цифр.

## Бустинг
<a id="boosting"></a>
([наверх](#sections))

Бустинг (англ. boosting — улучшение) — это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов. Бустинг представляет собой жадный алгоритм построения композиции алгоритмов. Изначально понятие бустинга возникло в работах по вероятно почти корректному обучению в связи с вопросом: возможно ли, имея множество плохих (незначительно отличающихся от случайных) алгоритмов обучения, получить хороший.

В течение последних 10 лет бустинг остаётся одним из наиболее популярных методов машинного обучения, наряду с нейронными сетями и машинами опорных векторов. Основные причины — простота, универсальность, гибкость (возможность построения различных модификаций), и, главное, высокая обобщающая способность.

Бустинг над [решающими деревьями](https://learnmachinelearning.wikia.org/ru/wiki/%D0%A0%D0%B5%D1%88%D0%B0%D1%8E%D1%89%D0%B5%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_(Decision_tree)) считается одним из наиболее эффективных методов с точки зрения качества [классификации](#classification). Во многих экспериментах наблюдалось практически неограниченное уменьшение частоты ошибок на независимой тестовой выборке по мере наращивания композиции. Более того, качество на тестовой выборке часто продолжало улучшаться даже после достижения безошибочного распознавания всей обучающей выборки. Это перевернуло существовавшие долгое время представления о том, что для повышения обобщающей способности необходимо ограничивать сложность алгоритмов. На примере бустинга стало понятно, что хорошим качеством могут обладать сколь угодно сложные композиции, если их правильно настраивать.

Впоследствии феномен бустинга получил теоретическое обоснование. Оказалось, что взвешенное голосование не увеличивает эффективную сложность алгоритма, а лишь сглаживает ответы базовых алгоритмов. Количественные оценки обобщающей способности бустинга формулируются в терминах отступа. Эффективность бустинга объясняется тем, что по мере добавления базовых алгоритмов увеличиваются отступы обучающих объектов. Причём бустинг продолжает раздвигать классы даже после достижения безошибочной классификации обучающей выборки.

К сожалению, теоретические оценки обобщающей способности дают лишь качественное обоснование феномену бустинга. Хотя они существенно точнее более общих [оценок Вапника-Червоненкиса](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%92%D0%B0%D0%BF%D0%BD%D0%B8%D0%BA%D0%B0_%E2%80%94_%D0%A7%D0%B5%D1%80%D0%B2%D0%BE%D0%BD%D0%B5%D0%BD%D0%BA%D0%B8%D1%81%D0%B0), всё же они сильно завышены, и требуемая длина обучающей выборки оценивается величиной порядка ![10^4 \dots 10^6](https://latex.codecogs.com/png.image?\dpi{110}%2010^4%20\dots%2010^6). Более основательные эксперименты показали, что иногда бустинг всё же переобучается.

## Метрики регрессии
<a id="Regression-metrics"></a>
([наверх](#sections))

**Средняя квадратическая ошибка (MSE)**

![MSE](https://www.machinelearningmastery.ru/img/0-798429-593663.png)

где yᵢ фактический ожидаемый результат и ŷᵢ это прогноз модели.

MSE в основном измеряет среднеквадратичную ошибку наших прогнозов. Для каждой точки вычисляется квадратная разница между прогнозами и целью, а затем усредняются эти значения.

Чем выше это значение, тем хуже модель. Он никогда не бывает отрицательным, поскольку мы возводим в квадрат отдельные ошибки прогнозирования, прежде чем их суммировать, но для идеальной модели это будет ноль.

Преимущество:Полезно, если у нас есть неожиданные значения, о которых мы должны заботиться. Очень высокое или низкое значение, на которое мы должны обратить внимание.

Недостаток:Если мы сделаем один очень плохой прогноз, возведение в квадрат сделает ошибку еще хуже, и это может исказить метрику в сторону переоценки плохости модели. Это особенно проблематичное поведение, если у нас есть зашумленные данные (то есть данные, которые по какой-либо причине не совсем надежны) - даже в «идеальной» модели может быть высокий MSE в этой ситуации, поэтому становится трудно судить, насколько хорошо модель выполняет. С другой стороны, если все ошибки малы или, скорее, меньше 1, то ощущается противоположный эффект: мы можем недооценивать недостатки модели.

**Среднеквадратическая ошибка (RMSE)**

RMSE - это просто квадратный корень из MSE. Квадратный корень введен, чтобы масштаб ошибок был таким же, как масштаб целей.

Важно понять, в каком смысле RMSE похож на MSE, и в чем разница.

Во-первых, они похожи с точки зрения их минимизаторов, каждый минимизатор MSE также является минимизатором для RMSE и наоборот, поскольку квадратный корень является неубывающей функцией. Например, если у нас есть два набора предсказаний, A и B, и скажем, что MSE для A больше, чем MSE для B, то мы можем быть уверены, что RMSE для A больше RMSE для B. И это также работает в противоположном направлении.

**Средняя абсолютная ошибка (MAE)**

В MAE ошибка рассчитывается как среднее абсолютных разностей между целевыми значениями и прогнозами. MAE - это линейная оценка, которая означает, что все индивидуальные различия взвешены одинаковов среднем. Например, разница между 10 и 0 будет вдвое больше разницы между 5 и 0. Однако то же самое не верно для RMSE. Математически он рассчитывается по следующей формуле:

![MAE](https://www.machinelearningmastery.ru/img/0-411862-507651.png)

Что важно в этой метрике, так это то, что она наказывает огромные ошибки, которые не так плохо, как MSE.Таким образом, он не так чувствителен к выбросам, как среднеквадратическая ошибка.

**R в квадрате (R²)**

Коэффициент детерминации, или R² (иногда читаемый как R-два), является еще одним показателем, который мы можем использовать для оценки модели, и он тесно связан с MSE, но имеет преимущество в том, что безмасштабное не имеет значения, являются ли выходные значения очень большими или очень маленькими,R² всегда будет между -∞ и 1.

Когда R² отрицательно, это означает, что модель хуже, чем предсказание среднего значения.

![R²](https://www.machinelearningmastery.ru/img/0-582527-102961.png)

R² - это соотношение между тем, насколько хороша наша модель, и тем, насколько хороша модель наивного среднего.

## Обучение с помощью градиентного спуска
<a id="gradient-descent-training"></a>
([наверх](#sections))

Градиентный спуск — самый используемый алгоритм обучения, он применяется почти в каждой модели машинного обучения. Градиентный спуск — это, по сути, и есть то, как обучаются модели. Метод градиентного спуска с некоторой модификацией широко используется для обучения персептрона и глубоких нейронных сетей, и известен как метод обратного распространения ошибки.

**Что такое градиентный спуск**  
Градиентный спуск — метод нахождения минимального значения функции потерь (существует множество видов этой функции). Минимизация любой функции означает поиск самой глубокой впадины в этой функции. Функция используется, чтобы контролировать ошибку в прогнозах модели машинного обучения. Поиск минимума означает получение наименьшей возможной ошибки или повышение точности модели. Мы увеличиваем точность, перебирая набор учебных данных при настройке параметров нашей модели (весов и смещений).

Итак, градиентный спуск нужен для минимизации функции потерь.

**Градиент** - это вектор, касающийся функции и указывающий в направлении наибольшего увеличения этой функции. Градиент равен нулю при локальном максимуме или минимуме, потому что нет единого направления увеличения. В математике градиент определяется как частная производная для каждой входной переменной функции. Например, у нас есть функция:

![Градиент](https://www.machinelearningmastery.ru/img/0-629980-531134.gif)

Поскольку градиент - это вектор, указывающий на наибольшее увеличение функции, отрицательный градиент - это вектор, указывающий на наибольшее уменьшение функции. Следовательно, мы можем минимизировать функцию, итеративно немного двигаясь в направлении отрицательного градиента. Это логика градиентного спуска.

![ГрадСпуск](https://www.machinelearningmastery.ru/img/0-608727-517151.jpeg)

Важным параметром в градиентном спуске является скорость обучения, которая определяет размер каждого шага. Когда скорость обучения слишком велика, градиентный спуск может перепрыгнуть через долину и оказаться на другой стороне. Это приведет к расхождению функции стоимости. С другой стороны, когда скорость обучения слишком мала, алгоритм будет сходиться долго. Следовательно, перед началом градиентного спуска необходима правильная скорость обучения.

**Различные типы градиентного спуска**
Существует 3 варианта градиентного спуска:

1. Мini-batch: тут вместо перебирания всех примеров обучения и с каждой итерацией, выполняющей вычисления только на одном примере обучения, мы обрабатываем n учебных примеров сразу. Этот выбор хорош для очень больших наборов данных.

2. Стохастический градиентный спуск: в этом случае вместо использования и зацикливания на каждом примере обучения, мы просто используем один раз. Есть несколько вещей замечаний:

С каждой итерацией ГС вам нужно перемешать набор обучения и выбрать случайный пример обучения.
Поскольку вы используете только один пример обучения, ваш путь к локальным минимумам будет очень шумным, как у пьяного человека, который много выпил.

3. Пакетный градиентный спуск

Пакетный градиентный спуск использует всю партию обучающих данных на каждом шаге. Он рассчитывает ошибку для каждой записи и принимает среднее значение для определения градиента Преимущество Batch Gradient Descent заключается в том, что алгоритм более эффективен в вычислительном отношении и обеспечивает стабильный путь обучения, что облегчает сходимость. Тем не менее, пакетный градиентный спуск занимает больше времени, когда тренировочный набор большой.

## Алгоритмы кластеризации такие как k-means и c-means, dbscan
<a id="k-means-c-means-dbscan"></a>
([наверх](#sections))

## Иерархическая кластеризация
<a id="hierarchical-clustering"></a>
([наверх](#sections))

## Алгоритмы понижения размерности такие как PCA, t-SNE
<a id="lPCA-t-SNE"></a>
([наверх](#sections))

## Что такое регуляризация и чем она полезна?
<a id="regularization"></a>
([наверх](#sections))

Регуляризация – это метод добавления дополнительной информации к условию для решения некорректно поставленных задач или для предотвращения переобучения. Под регуляризацией часто понимается «штраф» за сложность модели.

термин изначально возник в теории [некорректно поставленных задач](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%80%D1%80%D0%B5%D0%BA%D1%82%D0%BD%D0%BE_%D0%BF%D0%BE%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0), т.е. задач , в которых не выполняются требования:

* решение существует,
* решение единственно,
* решение непрерывно зависит от данных.

Собственно, регуляризация (изначально в версии А. Н. Тихонова) борется со вторым и третьим пунктом с помощью дополнительных ограничений на решение. По факту: в задаче оптимизации к целевой функции добавляют регуляризационное слагаемое (т.н. штраф).

Сейчас термин стал намного шире: часто любой способ борьбы с переобучением, который касается настройки модели,  в машинном обучением называют регуляризацией (начиная от dropout и заканчивая prunning).

## Алгоритмы для нейронных сетей
<a id="algorithms-for-neural-networksn"></a>
([наверх](#sections))

## Полносвязная нейронная сеть
<a id="fully-connected-neural-network"></a>
([наверх](#sections))

## Свёрточная нейронная сеть
<a id="convolutional-neural-networkn"></a>
([наверх](#sections))

## Рекуррентная нейронная сеть
<a id="recurrent-neural-network"></a>
([наверх](#sections))

## Для каких задач подходит тот или иной алгоритм?
<a id="algorithm-suitable"></a>
([наверх](#sections))

## Что такое функция активации?
<a id="activation-function"></a>
([наверх](#sections))

Функция активации (англ. activation function) a(x) определяет выходное значение нейрона в зависимости от результата взвешенной суммы входов и порогового значения.


# Сеть
<a id="network"></a>

* [Что такое веб-сервисы?](#web-services)
* [REST](#rest)  
* [http](#http)
* [JSON](#json)
* [XML](#xml)
* [Очереди сообщений](#message-queues)
* [Что происходит в тот момент, когда вы вводите в адресной строке браузера URL сайта и нажимаете ввод?](#www)
* [Виды сетевых протоколов](#types-of-network-protocols)

([наверх](#sections))

## Что такое веб-сервисы?
<a id="web-services"></a>

([наверх](#sections))

Веб-сервисы (или веб-службы) — это технология, позволяющая системам обмениваться данными друг с другом через сетевое подключение. Обычно веб-сервисы работают поверх протокола HTTP или протокола более высокого уровня. Веб-сервис — просто адрес, ссылка, обращение к которому позволяет получить данные или выполнить действие.

Главное отличие веб-сервиса от других способов передачи данных: стандартизированность. Приняв решение использовать веб-сервисы, можно сразу переходить к структуре данных и доступным функциям. Например, В SOAP (как более строгом протоколе), уже решён вопрос уведомления об ошибках.

Самые известные способы реализации веб-сервисов:

* XML-RPC (XML Remote Procedure Call) — протокол удаленного вызова процедур с использованием XML. Прародитель SOAP. Предельно прост в реализации.

* SOAP (Simple Object Access Protocol) — стандартный протокол по версии W3C. Четко структурирован и задокументирован.

* JSON-RPC (JSON Remote Procedure Call) — более современный аналог XML-RPC. Основное отличие — данные передаются в формате JSON.

* REST (Representational State Transfer) — архитектурный стиль взаимодействия компьютерных систем в сети основанный на методах протокола HTTP.

* Специализированные протоколы для конкретного вида задач, такие как GraphQL.

* Менее распространенный, но более эффективный gRPC, передающий данные в бинарном виде и использующий HTTP/2 в качестве транспорта.

## REST
<a id="rest"></a>

([наверх](#sections))

REST (Representational state transfer) – это стиль архитектуры программного обеспечения для распределенных систем, таких как World Wide Web, который, как правило, используется для построения веб-служб (набор рекомендаций, который позволяет унифицировать взаимодействие клиентских и серверных приложений). Термин REST был введен в 2000 году Роем Филдингом, одним из авторов HTTP-протокола. Системы, поддерживающие REST, называются RESTful-системами. Единого стандарта у него нет — не протокол, а целый архитектурный стиль. Этим она отличается от многих аналогичных. При этом допустимо использовать XML, HTTP, JSON и URL.

REST не использует конвертацию данных при передаче, данные передаются в исходном виде — это снижает нагрузку на клиент веб-сервиса, но увеличивает нагрузку на сеть. Управление данными происходит с помощью методов HTTP:

GET — получить данные;

POST — добавить данные;

PUT — изменить данные;

DELETE — удалить данные.


В качестве пакета обычно отправляется JSON массив на указанный конкретный URL. Там срабатывает так называемая функция, а в зависимости от уже отправленных данных и текущего запроса начинается определенное действие.

Использование этих методов позволяет реализовать типичный CRUD (Create/Read/Update/Delete) для любой информации. Но это лишь соглашение: часто используются только 2 метода: GET для получения и POST для всего остального. Разобраться поможет такое понятие, как REST-Patterns . Паттерны связывают HTTP методы с тем, что они делают.

Преимущества:

* простота реализации;

* экономичность в плане ресурсов;

* не требует программных надстроек (json_decode есть почти в каждом языке).

Недостатки:

* отсутствие спецификации;

* неоднозначность методов управления данными.

Протокол по типу концентрированного REST API, работающий по HTTP = качественным веб-сервисам  

Так можно назвать веб-приложение, которое представляет ресурсы в формате, подходящем для других компьютеров. Они включают в себя разные интерфейсы.

Те варианты, которые применяются для транслирования, тоже можно учитывать как «веб-сервисы». Клиент, который пользуется этим, способен запросить все что угодно, а сервер ему отвечает и предоставляет результаты. Задействуют любой удобный язык программирования или подходящие платформы. Не имеет никакого значения, какой конкретно использовался, так как все выполняется через общий тип.

Когда API документируется, то неважно, чем пользовались разработчики при его создании — Ruby это был, Java или Python или что-то принципиально другое. Все запросы высылаются через один и тот же HTTP, решения приходят таким же способом.

## JSON
<a id="json"></a>

([наверх](#sections))

JSON это сокращение от JavaScript Object Notation — формата передачи данных. Как можно понять из названия, JSON произошел из JavaScript, но он доступен для использования на многих других языках, включая Python, Ruby, PHP и Java.  
JSON - один из самых популярных методов обмена данными между сервером и клиентом в Интернет (API и REST)

Сам по себе JSON использует расширение .json. Когда же он определяется в других файловых форматах, как .html, он появляется в кавычках как JSON строка или может быть объектом, назначенным на переменную. Такой формат легко передавать между сервером и клиентской частью, ну или браузером.  
Легкочитаемый и компактный, JSON представляет собой хорошую альтернативу XML и требует куда меньше форматирования контента. Это информативное руководство поможет вам быстрее разобраться с данными, которые вы можете использовать с JSON и основной структурой с синтаксисом этого же формата.

Анализ структура JSON
![Анализ структура JSON](https://habrastorage.org/webt/x6/q_/sg/x6q_sgnunckncpntu5xyf7zeu1i.png)

**Синтаксис и структура**

Объект JSON это формат данных — ключ-значение, который обычно рендерится в фигурных скобках. 

JSON объект:

```
{
  "first_name" : "Sammy",
  "last_name" : "Shark",
  "location" : "Ocean",
  "online" : true,
  "followers" : 987 
}
```
JSON может содержать другие вложенные объекты в JSON, в дополнение к вложенным массивам. Такие объекты и массивы будут передаваться, как значения назначенные ключам и будут представлять собой связку ключ-значение.

Вынесем имя из первого json объекта и добавим ещё три.
```
{ 
  "sammy" : {
    "username"  : "SammyShark",
    "location"  : "Indian Ocean",
    "online"    : true,
    "followers" : 987
  },
  "jesse" : {
    "username"  : "JesseOctopus",
    "location"  : "Pacific Ocean",
    "online"    : false,
    "followers" : 432
  },
  "drew" : {
    "username"  : "DrewSquid",
    "location"  : "Atlantic Ocean",
    "online"    : false,
    "followers" : 321
  },
  "jamie" : {
    "username"  : "JamieMantisShrimp",
    "location"  : "Pacific Ocean",
    "online"    : true,
    "followers" : 654
  }
}
```

Вложенные массивы
Данные также могут быть вложены в формате JSON, используя JavaScript массивы, которые передаются как значения. JavaScript использует квадратные скобки [ ] для формирования массива. Массивы по своей сути — это упорядоченные коллекции и могут включать в себя значения совершенно разных типов данных.  
Мы можем использовать массив при работе с большим количеством данных, которые могут быть легко сгруппированны вместе, как например, если есть несколько разных сайтов и профайлов в социальных сетях ассоциированных с одним пользователем.

```
{ 
  "first_name" : "Sammy",
  "last_name" : "Shark",
  "location" : "Ocean",
  "websites" : [ 
    {
      "description" : "work",
      "URL" : "https://www.digitalocean.com/"
    },
    {
      "desciption" : "tutorials",
      "URL" : "https://www.digitalocean.com/community/tutorials"
    }
  ],
  "social_media" : [
    {
      "description" : "twitter",
      "link" : "https://twitter.com/digitalocean"
    },
    {
      "description" : "facebook",
      "link" : "https://www.facebook.com/DigitalOceanCloudHosting"
    },
    {
      "description" : "github",
      "link" : "https://github.com/digitalocean"
    }
  ]
}
```

## XML
<a id="xml"></a>

([наверх](#sections))

Начнём с сравнения с JSON

XML расшифровывается как eXtensible Markup Language. Это способ хранения данных, которые могут быть прочитаны как людьми, так и машинами. Формат XML доступен для использования во многих языках программирования.  
Во многих случаях, XML очень схож с JSON. XML должен быть спарсен с XML парсером, но JSON может быть спарсен стандартным функционалом. Так же, в отличие от JSON, XML не может использовать массивы.
```
<users>
    <user>
        <username>SammyShark</username> <location>Indian Ocean</location>
    </user>
    <user>
        <username>JesseOctopus</username> <location>Pacific Ocean</location>
    </user>
    <user>
        <username>DrewSquir</username> <location>Atlantic Ocean</location>
    </user>
    <user>
        <username>JamieMantisShrimp</username> <location>Pacific Ocean</location>
    </user>
</users>
```

А вот это уже формат JSON:
```
{"users": [
  {"username" : "SammyShark", "location" : "Indian Ocean"},
  {"username" : "JesseOctopus", "location" : "Pacific Ocean"},
  {"username" : "DrewSquid", "location" : "Atlantic Ocean"},
  {"username" : "JamieMantisShrimp", "location" : "Pacific Ocean"}
] }
```
Простейший XML-документ выглядит следующим образом:
```
<?xml version="1.0" encoding="windows-1251"?>
<book category="WEB">
   <title lang="en">Learning XML</title>
   <author>Erik T. Ray</author>
   <year>2003</year>
   <price></price>
</book>
```

Первая строка — это XML декларация. Здесь определяется версия XML (1.0) и кодировка файла. На следующей строке описывается корневой элемент документа ```<book>``` (открывающий тег). Следующие 4 строки описывают дочерние элементы корневого элемента (```title```, ```author```, ```year```, ```price```). Последняя строка определяет конец корневого элемента ```</book>``` (закрывающий тег).

Документ XML состоит из элементов (elements). Элемент начинается открывающим тегом (start-tag) в угловых скобках, затем идет содержимое (content) элемента, после него записывается закрывающий тег (end-teg) в угловых скобках.

Информация, заключенная между тегами, называется содержимым или значением элемента: ```<author>Erik T. Ray</author>```. Т.е. элемент ```author``` принимает значение ```Erik T. Ray```. Элементы могут вообще не принимать значения.

Элементы могут содержать атрибуты, так, например, открывающий тег ```<title lang="en">``` имеет атрибут ```lang```, который принимает значение ```en```. Значения атрибутов заключаются в кавычки (двойные или ординарные).

Некоторые элементы, не содержащие значений, допустимо записывать без закрывающего тега. В таком случае символ ```/``` ставится в конце открывающего тега:

```<name first="Иван" second="Петрович" />```

**Структура XML**  

XML документ должен содержать корневой элемент. Этот элемент является «родительским» для всех других элементов.

Все элементы в XML документе формируют иерархическое дерево. Это дерево начинается с корневого элемента и разветвляется на более низкие уровни элементов.

Все элементы могут иметь подэлементы (дочерние элементы):

```
<корневой>
   <потомок>
     <подпотомок>.....</подпотомок>
   </потомок>
</корневой>
```

**Правила синтаксиса (Валидность)**  

Структура XML документа должна соответствовать определенным правилам. XML документ отвечающий этим правилам называется валидным (англ. Valid — правильный) или синтаксически верным. Соответственно, если документ не отвечает правилам, он является невалидным .

Основные правила синтаксиса XML:

1. Теги XML регистрозависимы — теги XML являются регистрозависимыми. Так, тег ```<Letter>``` не то же самое, что тег ```<letter>```.

Открывающий и закрывающий теги должны определяться в одном регистре:
```
<Message>Это неправильно</message>
<message>Это правильно</message>
```

2. XML элементы должны соблюдать корректную вложенность:
```
<b><i>Некорректная вложенность</b></i>
<b><i>Корректная вложенность</i></b>
```

3. У XML документа должен быть корневой элемент — XML документ должен содержать один элемент, который будет родительским для всех других элементов. Он называется корневым элементом.

4. Значения XML атрибутов должны заключаться в кавычки:

```
<note date="12/11/2007">Корректная запись</note>
<note date=12/11/2007>Некорреткная запись</note>
```

**Сущности**  

Некоторые символы в XML имеют особые значения и являются служебными. Если вы поместите, например, символ ```<``` внутри XML элемента, то будет сгенерирована ошибка, так как парсер интерпретирует его, как начало нового элемента.

В примере ниже будет сгенерирована ошибка, так как в значении ```"ООО<Мосавтогруз>"``` атрибута ```НаимОрг``` содержатся символы ```<``` и ```>```.  
```
<НПЮЛ ИННЮЛ="7718962261" КПП="771801001" НаимОрг="ООО<Мосавтогруз>"/>
```
Также ошибка будет сгенерирована и в слудющем примере, если название организации взять в обычные кавычки (английские двойные):
```
<НПЮЛ ИННЮЛ="7718962261" КПП="771801001" НаимОрг="ООО"Мосавтогруз""/>
```
Чтобы ошибки не возникали, нужно заменить символ ```<``` на его сущность. В XML существует 5 предопределенных сущностей:

| *Сущность*     | *Символ*      | *Значение*|
|:------------:|:--------------:| :---:|
| ```&lt;```        | 	<	        | меньше, чем |
| ```&gt;```        | 	>         | больше, чем |
| ```&amp;```        | 	&      | амперсанд|
| ```&apos;```     | 	'        | апостроф |
| ```&quot;```        | 	"        | кавычки |

Таким образом, корректными будут следующие формы записей:
``` 
<НПЮЛ ИННЮЛ="7718962261" КПП="771801001" НаимОрг="ООО&quot;Мосавтогруз&quot;"/>
``` 
или
``` 
<НПЮЛ ИННЮЛ="7718962261" КПП="771801001" НаимОрг="ООО«Мосавтогруз»"/>
``` 
В последнем примере английские двойные кавычки заменены на французские кавычки («ёлочки»), которые не являются служебными символами.

**XSD схема**  

XML Schema — язык описания структуры XML-документа, его также называют XSD. Как большинство языков описания XML, XML Schema была задумана для определения правил, которым должен подчиняться документ. Но, в отличие от других языков, XML Schema была разработана так, чтобы её можно было использовать в создании программного обеспечения для обработки документов XML.

После проверки документа на соответствие XML Schema читающая программа может создать модель данных документа, которая включает:

словарь (названия элементов и атрибутов);
модель содержания (отношения между элементами и атрибутами и их структура);
типы данных.
Каждый элемент в этой модели ассоциируется с определённым типом данных, позволяя строить в памяти объект, соответствующий структуре XML-документа. Языкам объектно-ориентированного программирования гораздо легче иметь дело с таким объектом, чем с текстовым файлом.

Простой пример схемы на XML Schema, расположенной в файле "country.xsd" и описывающей данные о населении страны:

``` 
<?xml version="1.0" encoding="utf-8"?>
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema">
  <xs:element name="country">
    <xs:complexType>
      <xs:sequence>
        <xs:element name="country_name" type="xs:string"/>
        <xs:element name="population" type="xs:decimal"/>
      </xs:sequence>
    </xs:complexType>
  </xs:element>
</xs:schema>
``` 
Пример документа, соответствующего этой схеме:

``` 
<?xml version="1.0" encoding="utf-8"?>
<country>
    <country_name>France</country_name>
    <population>59.7</population>
</country>
``` 

## http
<a id="http"></a>

([наверх](#sections))

HTTP — это протокол, позволяющий получать различные ресурсы, например HTML-документы. Протокол HTTP лежит в основе обмена данными в Интернете. HTTP является протоколом клиент-серверного взаимодействия, что означает инициирование запросов к серверу самим получателем, обычно веб-браузером (web-browser). Полученный итоговый документ будет (может) состоять из различных поддокументов, являющихся частью итогового документа: например, из отдельно полученного текста, описания структуры документа, изображений, видео-файлов, скриптов и многого другого.

Когда мы вводим в браузере URL-адрес, например www.google.com, на сервер отправляется запрос на веб-сайт, идентифицированный URL-адресом.
Затем этот сервер формирует и выдает ответ. Важным является формат этих запросов и ответов. Эти форматы определяются протоколом HTTP — Hyper Text Transfer Protocol.

Когда мы набираем URL в браузере, он отправляет запрос GET на указанный сервер. Затем сервер отвечает HTTP-ответом, который содержит данные в формате HTML — Hyper Text Markup Language. Затем браузер получает этот HTML-код и отображает его на экране.

Допустим, мы заполняем форму, присутствующую на веб-странице, со списком элементов. В таком случае, когда мы нажимаем кнопку «Submit» (Отправить), HTTP-запрос POST отправляется на сервер.

HTTP — это клиент-серверный протокол, то есть запросы отправляются какой-то одной стороной — участником обмена (user-agent) (либо прокси вместо него). Чаще всего в качестве участника выступает веб-браузер, но им может быть кто угодно, например, робот, путешествующий по Сети для пополнения и обновления данных индексации веб-страниц для поисковых систем.

Каждый запрос (англ. request) отправляется серверу, который обрабатывает его и возвращает ответ (англ. response). Между этими запросами и ответами как правило существуют многочисленные посредники, называемые прокси, которые выполняют различные операции и работают как шлюзы или кеш, например.

## Очереди сообщений
<a id="message-queues"></a>

([наверх](#sections))

**Sync vs Async: синхронное и асинхронное взаимодействие**

Очереди сообщений (Message Queue) — это форма асинхронной коммуникации между сервисами. Поэтому, прежде чем говорить о них, покажем на упрощенном, немного искусственном примере разницу между синхронным и асинхронным взаимодействием.

Предположим, вы разрабатываете сайт книжного магазина и у вас есть сервис, к которому обращается пользователь, например отправка рецензии на прочитанную книгу. При нажатии кнопки «Отправить» вызывается некоторый API, который, в свою очередь, может обратиться к другим API.

При синхронном взаимодействии все запросы в этой цепочке вызовов выполняются строго друг за другом, а при выполнении последнего запроса ответы последовательно передаются в обратном направлении. В итоге пользователь вынужден пару секунд ждать сообщения о публикации своего отзыва, хотя его не интересуют особенности серверной обработки и он вполне обоснованно хочет увидеть сообщение сразу после нажатия кнопки. Конечно, время ожидания будет во многом определяться мощностью оборудования, но при пиковых нагрузках оно может стать серьезной проблемой.

Еще один недостаток такой схемы — обработка сбоев. Если на одном из шагов возникнет исключение, оно каскадно возвратится назад, и пользователь получит уведомление об ошибке с просьбой повторно отправить рецензию. Вряд ли кого-то обрадует получение подобного сообщения после длительного ожидания.  

Синхронное взаимодействие на основе REST API  

![Синхронное взаимодействие на основе REST API](https://mcs.mail.ru/wp-content/uploads/2021/02/1-4.png)

Описанную схему можно изменить, добавив асинхронные вызовы. Достаточно вызвать в асинхронном режиме первый REST API и параллельно вернуть пользователю сообщение о том, что его рецензия принята и будет размещена, например, в течение суток. В итоге сайт не блокируется, а вызовы всех последующих API происходят независимо от пользователя.

Но у такой схемы также есть существенный недостаток: в случае сбоя в одном из API информация, введенная пользователем, будет потеряна. Если в первом примере в случае ошибок достаточно повторно отправить рецензию, то здесь ее необходимо заполнить заново.

Вариант асинхронного взаимодействия на основе REST API

![Вариант асинхронного взаимодействия на основе REST API](https://mcs.mail.ru/wp-content/uploads/2021/02/2-2.png)

Для устранения недостатков обеих схем как раз и предназначены очереди сообщений.

**Принципы работы очередей сообщений**

Очереди предоставляют буфер для временного хранения сообщений и конечные точки, которые позволяют подключаться к очереди для отправки и получения сообщений в асинхронном режиме.

В сообщениях могут содержаться запросы, ответы, ошибки и иные данные, передаваемые между программными компонентами. Компонент, называемый производителем (Producer), добавляет сообщение в очередь, где оно будет храниться, пока другой компонент, называемый потребителем (Consumer), не извлечет сообщение и не выполнит с ним необходимую операцию.

Очередь сообщений

![Очередь сообщений](https://mcs.mail.ru/wp-content/uploads/2021/02/3-2.png)

Очереди поддерживают получение сообщений как методом Push, так и методом Pull:  
* метод Pull подразумевает периодический опрос очереди получателем по поводу наличия новых сообщений;
* метод Push — отправку уведомления получателю в момент прихода сообщения. Второй метод реализует модель «Издатель/Подписчик» (Publisher/Subscriber).
Так как очереди могут использоваться несколькими производителями и потребителями одновременно, обычно их реализуют с помощью дополнительной системы, называемой брокером. Брокер сообщений (Message Broker) занимается сбором и маршрутизацией сообщений на основе предопределенной логики. Сообщения могут передаваться с некоторым ключом — по этому ключу брокер понимает, в какую из очередей (одну или несколько) должно попасть сообщение.

Вернемся к примеру с отправкой рецензии. Пусть та часть сервиса, к которому обращается пользователь, выступит в качестве производителя и будет направлять запросы на создание рецензий в очередь. Сразу после добавления сообщения в очередь пользователю можно направлять уведомление об успехе операции. Вся последующая логика обработки будет выполняться независимо от него на стороне потребителя, подписанного на очередь.

Завершив обработку, потребитель отправит подтверждение в очередь, после чего исходное сообщение будет удалено. Но если во время обработки произойдет сбой и подтверждение не будет получено вовремя, сообщение может быть повторно извлечено потребителем из очереди.

Вариант асинхронного взаимодействия на основе очереди сообщений

![Вариант асинхронного взаимодействия на основе очереди сообщений](https://i2.wp.com/mcsjournal.ru/wp-content/uploads/2021/02/4-3.png?resize=1024%2C112&ssl=1)

Таким образом, использование очередей сообщений решает сразу две задачи: сокращает время ожидания пользователя за счет асинхронной обработки и предотвращает потерю информации при сбоях. Но не следует рассматривать очереди как универсальное средство для любого вида приложений: как и у любого инструмента, у них есть свои преимущества и недостатки, о которых мы поговорим ниже.

**Польза и преимущества очередей сообщений в микросервисной архитектуре**

Используя очереди сообщений в качестве основного средства взаимодействия микросервисов (Microservices Communication), можно добиться следующих преимуществ:

1. Отделение логически независимых компонентов друг от друга (Decoupling)  
Отличительная черта микросервисов — их автономность. И очереди во многом помогают уменьшить зависимости между ними. Каждое сообщение, передаваемое в очереди, — это всего лишь массив байтов с некоторыми метаданными. Метаданные нужны для направления в конкретную очередь, а информация, содержащаяся в основной части (теле) сообщения, может быть практически любой. Брокер не анализирует данные, он выступает лишь в качестве маршрутизатора. Это позволяет настроить взаимодействие между компонентами, работающими даже на разных языках и платформах.

2. Улучшение масштабируемости  
Очереди сообщений упрощают независимое масштабирование микросервисов. Наблюдая за состоянием очередей, можно масштабировать те сервисы, на которые приходится большая часть нагрузки. Кроме этого, очереди легко позволяют не только увеличивать число экземпляров существующих сервисов, но и добавлять новые с минимальным временем простоя. Все, что для этого требуется, — добавить нового потребителя, прослушивающего события в очереди.

Однако сами очереди также необходимо масштабировать, и это может создать дополнительные сложности.

3. Балансировка нагрузки  
Если один из сервисов не справляется с нагрузкой, требуется возможность запускать больше его экземпляров быстро и без дополнительных настроек. Обычно для этих целей используют балансировщик нагрузки, интегрированный с сервером обнаружения служб и предназначенный для распределения трафика. При использовании очередей сообщений сам брокер по умолчанию является балансировщиком нагрузки. Если несколько потребителей слушают очередь одновременно, сообщения будут распределяться между ними в соответствии с настроенной стратегией.

4. Повышение надежности  
Выход из строя одного из компонентов не сказывается на работе всей системы: при восстановлении он обработает сообщение, находящееся в очереди. Ваш веб-сайт по-прежнему может работать, даже если задерживается часть обработки заказа, например, из-за проблем с сервером БД или системой электронной почты.

Правда, при этом очередь сама приобретает статус SPoF (Single Point Of Failure), поэтому необходимо заранее предусмотреть действия на случай ее аварийного отключения.

5. Безопасность
Большинство брокеров выполняют аутентификацию приложений, которые пытаются получить доступ к очереди, и позволяют использовать шифрование сообщений как при их передаче по сети, так и при хранении в самой очереди. Таким образом, очередь снимает с ваших сервисов бремя организации авторизации запросов.

**Варианты использования очередей сообщений**  

Очереди сообщений полезны в тех случаях, где возможна асинхронная обработка. Рассмотрим наиболее частые сценарии использования очередей сообщений (Message Queue use Cases):

1. Фоновая обработка долгосрочных задач на веб-сайтах
Сюда можно отнести задачи, которые не связаны напрямую с основным действием пользователя сайта и могут быть выполнены в фоновом режиме без необходимости ожидания с его стороны. Это обработка изображений, преобразование видео в различные форматы, создание отзывов, индексирование в поисковых системах после изменения данных, отправка электронной почты, формирование файлов и так далее.

2. Буферизация при пакетной обработке данных
Очереди можно использовать в качестве буфера для некоторой массовой обработки, например пакетной вставки данных в БД или HDFS. Очевидно, что гораздо эффективнее добавлять сто записей за раз, чем по одной сто раз, так как сокращаются накладные расходы на инициализацию и завершение каждой операции. Но для стандартной архитектуры может стать проблемой генерация данных клиентской службой быстрее, чем их может обработать получатель. Очередь же предоставляет временное хранилище для пакетов с данными, где они будут храниться до завершения обработки принимающей стороной.

3. Отложенные задачи
Многие системы очередей позволяют производителю указать, что доставка сообщений должна быть отложена. Это может быть полезно при реализации льготных периодов. Например, вы разрешаете покупателю отказаться от размещения заказа в течение определенного времени и ставите отложенное задание в очередь. Если покупатель отменит операцию в указанный срок, сообщение можно удалить из очереди.

4. Сглаживание пиковых нагрузок
Помещая данные в очередь, вы можете быть уверены, что данные будут сохранены и в конечном итоге обработаны, даже если это займет немного больше времени, чем обычно, из-за большого скачка трафика. Увеличить скорость обработки в таких случаях также возможно — за счет масштабирования нужных обработчиков.

5. Гарантированная доставка при нестабильной инфраструктуре
Нестабильная сеть в сочетании с очередью сообщений создает надежный системный ландшафт: каждое сообщение будет отправлено, как только это будет технически возможно.

6. Упорядочение транзакций
Многие брокеры поддерживают очереди FIFO, полезные в системах, где важно сохранить порядок транзакций. Если 1000 человек размещают заказ на вашем веб-сайте одновременно, это может создать некоторые проблемы с параллелизмом и не будет гарантировать, что первый заказ будет выполнен первым. С помощью очереди можно определить порядок их обработки.

7. Сбор аналитической информации
Очереди часто применяют для сбора некоторой статистики, например использования определенной системы и ее функций. Как правило, моментальная обработка такой информации не требуется. Когда сообщения поступают в веб-службу, они помещаются в очередь, а затем при помощи дополнительных серверов приложений обрабатываются и отправляются в базу данных.

8. Разбиение трудоемких задач на множество маленьких частей
Если у вас есть некоторая задача для группы серверов, то вам необходимо выполнить ее на каждом сервере. Например, при редактировании шаблона мониторинга потребуется обновить мониторы на каждом сервере, использующем этот шаблон. Вы можете поставить сообщение в очередь для каждого сервера и выполнять их одновременно в виде небольших операций.

9. Прочие сценарии, требующие гарантированной доставки информации и высокого уровня отказоустойчивости
Это обработка финансовых транзакций, бронирование авиабилетов, обновление записей о пациентах в сфере здравоохранения и так далее.

**Сложности использования и недостатки очередей сообщений: как с ними справляться**

Несмотря на многочисленные преимущества очередей сообщений, самостоятельное их внедрение может оказаться довольно сложной задачей по нескольким причинам:

* По сути, это еще одна система, которую необходимо купить/установить, правильно сконфигурировать и поддерживать. Также потребуются дополнительные мощности.
* Если брокер когда-либо выйдет из строя, это может остановить работу многих систем, взаимодействующих с ним. Как минимум необходимо позаботиться о резервном копировании данных.
* С ростом числа очередей усложняется и отладка. При синхронной обработке сразу очевидно, какой запрос вызвал сбой, например, благодаря иерархии вызовов в IDE. В очередях потребуется позаботиться о системе трассировки, чтобы быстро связать несколько этапов обработки одного запроса для обнаружения причины ошибки.
* При использовании очередей вы неизбежно столкнетесь с выбором стратегии доставки сообщений. В идеале сообщения должны обрабатываться каждым потребителем однократно. Но на практике это сложно реализовать из-за несовершенства сетей и прочей инфраструктуры. Большинство брокеров поддерживают две стратегии: доставка хотя бы раз (At-least-once) или максимум раз (At-most-once). Первая может привести к дубликатам, вторая — к потере сообщений. Обе требуют тщательного мониторинга. Некоторые брокеры также гарантируют строго однократную доставку (Exactly-once) с использованием порядковых номеров пакетов данных, но даже в этом случае требуется дополнительная проверка на стороне получателя.

**В каких случаях очереди неэффективны**  

Конечно, очереди не являются универсальным средством для любых приложений. Рассмотрим варианты, когда очереди не будут самым эффективным решением:

* У вашего приложения простая архитектура и функции, и вы не ожидаете его роста. Важно понимать, что очереди сообщений — это дополнительная сложность. Эту систему также необходимо настраивать, поддерживать, осуществлять мониторинг ее работы и так далее. Да, можно использовать Managed-решение, но вряд ли это будет оправдано для небольших приложений. Добавление очередей должно упрощать архитектуру, а не усложнять ее.
* Вы используете монолитное программное обеспечение, в котором развязка (Decoupling) невозможна или не приоритетна. Если вы не планируете разбивать монолит на микросервисы, но вам требуется асинхронность — для ее реализации обычно достаточно стандартной многопоточной модели. Очереди могут оказаться избыточным решением до тех пор, пока не возникнет явная необходимость в разделении приложения на автономные компоненты, способные независимо выполнять задачи.

## Что происходит в тот момент, когда вы вводите в адресной строке браузера URL сайта и нажимаете ввод?
<a id="www"></a>

([наверх](#sections))

## Виды сетевых протоколов
<a id="types-of-network-protocols"></a>

([наверх](#sections))

TCP/IP – совокупность протоколов передачи информации. TCP/IP – это особое обозначение всей сети, которая функционирует на основе протоколов TCP, а также IP.

TCP – вид протокола, который является связующим звеном для установки качественного соединения между 2 устройствами, передачи данных и верификации их получения.

IP – протокол, в функции которого входит корректность доставки сообщений по выбранному адресу. При этом информация делится на пакеты, которые могут поставляться по-разному.

MAC – вид протокола, на основании которого происходит процесс верификации сетевых устройств. Все устройства, которые подключены к сети Интернет, содержат свой оригинальный MAC-адрес.

ICMP – протокол, который ответственен за обмен данными, но не используется для процесса передачи информации.

UDP – протокол, управляющий передачей данных, но данные не проходят верификацию при получении. Этот протокол функционирует быстрее, чем протокол TCP.

HTTP – протокол для передачи информации (гипертекста), на базе которого функционируют все сегодняшние сайты. В его возможности входит процесс запрашивания необходимых данных у виртуально удаленной системы (файлы, веб-страницы и прочее).

FTP – протокол передачи информации из особого файлового сервера на ПК конечного пользователя.

POP3 – классический протокол простого почтового соединения, который ответственен за передачу почты.

SMTP – вид протокола, который может устанавливать правила для передачи виртуальной почты. Он ответственен за передачу и верификацию доставки, а также оповещения о возможных ошибках.


# Бизнес
<a id="business"></a>
([наверх](#sections))

* [UML-диаграммы](#uml)  

## UML-диаграммы
<a id="uml"></a>

* [Диаграмма классов](#class-diagram)  
* [Диаграмма компонентов](#component-diagram)
* [Диаграмма развертывания](#deployment-diagram)
* [Диаграмма объектов](#object-diagram)
* [Диаграмма пакетов](#package-diagram)
* [Диаграмма составной структуры](#composite-structure-diagram)
* [Диаграмма профилей](#profile-diagram)
* [Диаграмма прецедентов](#use-case-diagram)
* [Диаграмма деятельности](#activity-diagram)
* [Диаграмма состояний](#state-diagram)
* [Диаграмма последовательности](#sequence-diagram)
* [Диаграмма Коммуникации](#communication-diagram)
* [Диаграмма обзора взаимодействия](#interaction-overview-chart)
* [Временная диаграмма](#timing-diagram)

([наверх](#sections))

Unified Modeling Language (UML) — унифицированный язык моделирования. Modeling подразумевает создание модели, описывающей объект. Unified (универсальный, единый) — подходит для широкого класса проектируемых программных систем, различных областей приложений, типов организаций, уровней компетентности, размеров проектов. UML описывает объект в едином заданном синтаксисе, поэтому где бы вы не нарисовали диаграмму, ее правила будут понятны для всех, кто знаком с этим графическим языком — даже в другой стране.

**Для чего используется UML?**

Одна из задач UML — служить средством коммуникации внутри команды и при общении с заказчиком. Рассмотрим возможные варианты использования диаграмм. 

* Проектирование. UML-диаграммы помогут при моделировании архитектуры больших проектов, в которой можно собрать как крупные, так и более мелкие детали и нарисовать каркас (схему) приложения. По нему впоследствии будет строиться код.  

* Реверс-инжиниринг — создание UML-модели из существующего кода приложения, обратное построение. Может применяться, например, на проектах поддержки, где есть написанный код, но документация неполная или отсутствует. 

* Из моделей можно извлекать текстовую информацию и генерировать относительно удобочитаемые тексты — документировать. Текст и графика будут дополнять друг друга.
  
![Типы UML диаграмм](https://habrastorage.org/webt/ry/i-/-p/ryi--p6wtfhvszjhcbhaogsdz8w.png)

### Диаграмма классов
<a id="class-diagram"></a>

([наверх](#sections))

Диаграмма классов — это центральная методика моделирования, которая используется практически во всех объектно-ориентированных методах. Эта диаграмма описывает типы объектов в системе и различные виды статических отношений, которые существуют между ними.

Три наиболее важных типа отношений в диаграммах классов (на самом деле их больше), это:

* Ассоциация, которая представляет отношения между экземплярами типов, к примеру, человек работает на компанию, у компании есть несколько офисов.

* Наследование, которое имеет непосредственное соответствие наследованию в Объектно-Ориентированном дизайне.

* Агрегация, которая представляет из себя форму композиции объектов в объектно-ориентированном дизайне.

![Диаграммка классов](https://habrastorage.org/webt/_f/xw/jo/_fxwjox5thnp7l9c5yayfy4pa4m.jpeg)

### Диаграмма компонентов
<a id="component-diagram"></a>

([наверх](#sections))

На языке унифицированного моделирования диаграмма компонентов показывает, как компоненты соединяются вместе для формирования более крупных компонентов или программных систем.

Она иллюстрирует архитектуры компонентов программного обеспечения и зависимости между ними.

Эти программные компоненты включают в себя компоненты времени выполнения, исполняемые компоненты, а также компоненты исходного кода.

![Диаграмма компонентов](https://habrastorage.org/webt/ff/dr/83/ffdr83yesqcv78hua6zxt45tbye.jpeg)

### Диаграмма развертывания
<a id="deployment-diagram"></a>

([наверх](#sections))

Диаграмма развертывания помогает моделировать физический аспект объектно-ориентированной программной системы. Это структурная схема, которая показывает архитектуру системы, как развертывание (дистрибуции) программных артефактов.

Артефакты представляют собой конкретные элементы в физическом мире, которые являются результатом процесса разработки.

Диаграмма моделирует конфигурацию времени выполнения в статическом представлении и визуализирует распределение артефактов в приложении.

В большинстве случаев это включает в себя моделирование конфигураций оборудования вместе с компонентами программного обеспечения, на которых они размещены.

![Диаграмма развертывания](https://habrastorage.org/webt/hu/eq/h9/hueqh9ow4b15ivon2h5jahaxyck.jpeg)

### Диаграмма объектов
<a id="object-diagram"></a>

([наверх](#sections))

Статическая диаграмма объектов является экземпляром диаграммы класса; она показывает снимок подробного состояния системы в определенный момент времени. Разница в том, что диаграмма классов представляет собой абстрактную модель, состоящую из классов и их отношений.

Тем не менее, диаграмма объекта представляет собой экземпляр в конкретный момент, который имеет конкретный характер.Использование диаграмм объектов довольно ограничено, а именно — чтобы показать примеры структуры данных.

![Диаграмма объектов](https://habrastorage.org/webt/4v/lq/wn/4vlqwntp_ip8_jyyqm3s2goxk9a.jpeg)

### Диаграмма пакетов
<a id="package-diagram"></a>

([наверх](#sections))

Диаграмма пакетов — это структурная схема UML, которая показывает пакеты и зависимости между ними.

Она позволяет отображать различные виды системы, например, легко смоделировать многоуровневое приложение.

![Диаграмма пакетов](https://habrastorage.org/webt/x2/sm/5t/x2sm5tb7tz6lgeg0opfnrqmxnm8.jpeg)

### Диаграмма составной структуры
<a id="composite-structure-diagram"></a>

([наверх](#sections))

Диаграмма составной структуры аналогична диаграмме классов и является своего рода диаграммой компонентов, используемой в основном при моделировании системы на микроуровне, но она изображает отдельные части вместо целых классов. Это тип статической структурной диаграммы, которая показывает внутреннюю структуру класса и взаимодействия, которые эта структура делает возможными.

Эта диаграмма может включать внутренние части, порты, через которые части взаимодействуют друг с другом или через которые экземпляры класса взаимодействуют с частями и с внешним миром, и соединители между частями или портами. Составная структура — это набор взаимосвязанных элементов, которые взаимодействуют во время выполнения для достижения какой-либо цели. Каждый элемент имеет определенную роль в сотрудничестве.

![Диаграмма составной структуры](https://habrastorage.org/webt/xe/_q/mb/xe_qmbmhorarotvrzrzj-owtrtq.jpeg)

### Диаграмма профилей
<a id="profile-diagram"></a>

([наверх](#sections))

Диаграмма профилей позволяет нам создавать специфичные для домена и платформы стереотипы и определять отношения между ними. Мы можем создавать стереотипы, рисуя формы стереотипов и связывая их с композицией или обобщением через интерфейс, ориентированный на ресурсы. Мы также можем определять и визуализировать значения стереотипов.

![Диаграмма профилей](https://habrastorage.org/webt/jn/c2/8v/jnc28vsuumwxobgsxmvvszusz1i.jpeg)

### Диаграмма прецедентов
<a id="use-case-diagram"></a>

([наверх](#sections))

Диаграмма прецедентов описывает функциональные требования системы с точки зрения прецедентов. По сути дела, это модель предполагаемой функциональности системы (прецедентов) и ее среды (актеров).

Прецеденты позволяют связать то, что нам нужно от системы с тем, как система удовлетворяет эти потребности.

![Диаграмма прецедентов](https://habrastorage.org/webt/q7/tm/yr/q7tmyr_d_aosxppt8i6rbk20ggq.jpeg)

### Диаграмма деятельности
<a id="activity-diagram"></a>

([наверх](#sections))

Диаграммы деятельности представляют собой графическое представление рабочих процессов поэтапных действий и действий с поддержкой выбора, итерации и параллелизма.
Они описывают поток управления целевой системой, такой как исследование сложных бизнес-правил и операций, а также описание прецедентов и бизнес-процессов.
В UML диаграммы деятельности предназначены для моделирования как вычислительных, так и организационных процессов.

![Диаграмма деятельности](https://habrastorage.org/webt/5h/dm/mh/5hdmmhiwtzdrswnnw6vgqy8ezzw.jpeg)

### Диаграмма состояний
<a id="state-diagram"></a>

([наверх](#sections))

Диаграмма состояний — это тип диаграммы, используемый в UML для описания поведения систем, который основан на концепции диаграмм состояний Дэвида Харела. Диаграммы состояний отображают разрешенные состояния и переходы, а также события, которые влияют на эти переходы. Она помогает визуализировать весь жизненный цикл объектов и, таким образом, помогает лучше понять системы, основанные на состоянии.

![Диаграмма состояний](https://habrastorage.org/webt/wf/67/mr/wf67mrwroyogobe5agpoaj2juy8.jpeg)

### Диаграмма последовательности
<a id="sequence-diagram"></a>

([наверх](#sections))

Диаграмма последовательности моделирует взаимодействие объектов на основе временной последовательности. Она показывает, как одни объекты взаимодействуют с другими в конкретном прецеденте.

![Диаграмма последовательности](https://habrastorage.org/webt/wr/6n/26/wr6n26qbnsdpvlknj151uwatzvw.jpeg)

### Диаграмма Коммуникации
<a id="communication-diagram"></a>

([наверх](#sections))

Как и диаграмма последовательности, диаграмма коммуникации также используется для моделирования динамического поведения прецедента. Если сравнивать с Диаграммой последовательности, Диаграмма коммуникации больше сфокусирована на показе взаимодействия объектов, а не временной последовательности. На самом деле, диаграмма коммуникации и диаграмма последовательности семантически эквивалентны и могут перетекать одна в другую.

![Диаграмма Коммуникации](https://habrastorage.org/webt/sj/6h/gz/sj6hgzpzw-zsymldpiizkaap2rg.jpeg)

### Диаграмма обзора взаимодействия
<a id="interaction-overview-chart"></a>

([наверх](#sections))

Диаграмма обзора взаимодействий фокусируется на обзоре потока управления взаимодействиями. Это вариант Диаграммы деятельности, где узлами являются взаимодействия или события взаимодействия. Диаграмма обзора взаимодействий описывает взаимодействия, в которых сообщения и линии жизни скрыты. Мы можем связать «реальные» диаграммы и добиться высокой степени навигации между диаграммами внутри диаграммы обзора взаимодействия.

![Диаграмма обзора взаимодействия](https://habrastorage.org/webt/rk/8i/9l/rk8i9lhvjrrvsu8cuthg50fdx0s.jpeg)

### Временная диаграмма
<a id="timing-diagram"></a>

([наверх](#sections))

Временная диаграмма показывает поведение объекта (ов) в данный период времени. По сути — это особая форма диаграммы последовательности и различия между ними состоят в том, что оси меняются местами так, что время увеличивается слева направо, а линии жизни отображаются в отдельных отсеках, расположенных вертикально.

![Временная диаграмма](https://habrastorage.org/webt/fy/ea/gv/fyeagvt6jnk57o6hdkegem61lyi.jpeg)

# Источники
<a id="sources"></a>
([наверх](#sections))

* [Документация python](https://docs.python.org/3/library/)
* ["Как устроен Python. Гид для разработчиков, программистов и интересующихся" Мэтт Харрисон](https://t.me/pythonbooks/389)  
* [Магические методы Rafe Kettler](https://rszalski.github.io/magicmethods/)  
* [Техническая документация по SQL Server](https://docs.microsoft.com/ru-ru/sql/sql-server/?view=sql-server-ver15)  
* [SQL и NoSQL: разбираемся в основных моделях баз данных](https://tproger.ru/translations/sql-nosql-database-models/)  
* [Основные команды SQL, которые должен знать каждый программист](https://tproger.ru/translations/sql-recap/)  
* [Профессиональный информационно-аналитический ресурс, посвященный машинному обучению, распознаванию образов и интеллектуальному анализу данных](https://www.machinelearning.ru/)
* [Inside the Python GIL](http://www.dabeaz.com/python/GIL.pdf)
* [Журнал Mail.ru Cloud Solutions об IT-бизнесе, технологиях и цифровой трансформации](https://mcs.mail.ru/blog/)
* [Школа больших данных](https://www.bigdataschool.ru/)
* [Блог компании Тинькофф](https://habr.com/ru/company/tinkoff/profile/)
* [Блог Хекслета](https://ru.hexlet.io/blog)
