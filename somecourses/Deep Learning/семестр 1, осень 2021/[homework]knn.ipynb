{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4465735f",
   "metadata": {
    "id": "Twe_cnn5KxY6"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70667866",
   "metadata": {
    "id": "YD0NXyUYKxY7"
   },
   "source": [
    "Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59430a68",
   "metadata": {
    "id": "CTa2jNZkKxY8"
   },
   "source": [
    "<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80adb3",
   "metadata": {
    "id": "5H7wPU0IKxY-"
   },
   "source": [
    "\n",
    "Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n",
    "\n",
    "* Вычислить расстояние до каждого из объектов обучающей выборки\n",
    "* Отобрать объектов обучающей выборки, расстояние до которых минимально\n",
    "* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5994923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc1925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2683</td>\n",
       "      <td>333</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>2743</td>\n",
       "      <td>121</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>6572</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2915</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>4433</td>\n",
       "      <td>232</td>\n",
       "      <td>228</td>\n",
       "      <td>129</td>\n",
       "      <td>4019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2941</td>\n",
       "      <td>162</td>\n",
       "      <td>7</td>\n",
       "      <td>698</td>\n",
       "      <td>76</td>\n",
       "      <td>2783</td>\n",
       "      <td>227</td>\n",
       "      <td>242</td>\n",
       "      <td>148</td>\n",
       "      <td>1784</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3096</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>3303</td>\n",
       "      <td>231</td>\n",
       "      <td>202</td>\n",
       "      <td>99</td>\n",
       "      <td>5370</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2999</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>488</td>\n",
       "      <td>37</td>\n",
       "      <td>1532</td>\n",
       "      <td>228</td>\n",
       "      <td>225</td>\n",
       "      <td>131</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3088</td>\n",
       "      <td>217</td>\n",
       "      <td>21</td>\n",
       "      <td>295</td>\n",
       "      <td>53</td>\n",
       "      <td>2912</td>\n",
       "      <td>194</td>\n",
       "      <td>254</td>\n",
       "      <td>190</td>\n",
       "      <td>1590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2569</td>\n",
       "      <td>129</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>237</td>\n",
       "      <td>234</td>\n",
       "      <td>127</td>\n",
       "      <td>5094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2693</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2316</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "      <td>139</td>\n",
       "      <td>2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2536</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>277</td>\n",
       "      <td>19</td>\n",
       "      <td>323</td>\n",
       "      <td>222</td>\n",
       "      <td>216</td>\n",
       "      <td>128</td>\n",
       "      <td>2844</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3109</td>\n",
       "      <td>261</td>\n",
       "      <td>10</td>\n",
       "      <td>234</td>\n",
       "      <td>-8</td>\n",
       "      <td>2451</td>\n",
       "      <td>195</td>\n",
       "      <td>246</td>\n",
       "      <td>189</td>\n",
       "      <td>1853</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1   2    3   4     5    6    7    8     9  ...  45  46  47  48  \\\n",
       "0     2683  333  35   30  26  2743  121  173  179  6572  ...   0   0   0   0   \n",
       "1     2915   90   8  216  11  4433  232  228  129  4019  ...   0   0   0   0   \n",
       "2     2941  162   7  698  76  2783  227  242  148  1784  ...   0   0   0   0   \n",
       "3     3096   60  17  170   3  3303  231  202   99  5370  ...   0   0   0   0   \n",
       "4     2999   66   8  488  37  1532  228  225  131  2290  ...   0   0   0   0   \n",
       "...    ...  ...  ..  ...  ..   ...  ...  ...  ...   ...  ...  ..  ..  ..  ..   \n",
       "9995  3088  217  21  295  53  2912  194  254  190  1590  ...   0   0   0   0   \n",
       "9996  2569  129  10    0   0  1273  237  234  127  5094  ...   0   0   0   0   \n",
       "9997  2693   21  11   30   6  2316  212  216  139  2110  ...   0   0   0   0   \n",
       "9998  2536   42  11  277  19   323  222  216  128  2844  ...   0   0   0   0   \n",
       "9999  3109  261  10  234  -8  2451  195  246  189  1853  ...   0   0   0   0   \n",
       "\n",
       "      49  50  51  52  53  54  \n",
       "0      0   0   0   0   0   2  \n",
       "1      0   0   0   0   0   1  \n",
       "2      0   0   0   0   0   2  \n",
       "3      0   0   0   0   0   1  \n",
       "4      0   0   0   0   0   2  \n",
       "...   ..  ..  ..  ..  ..  ..  \n",
       "9995   0   0   0   0   0   2  \n",
       "9996   0   0   0   0   0   2  \n",
       "9997   0   0   0   0   0   2  \n",
       "9998   0   0   0   0   0   2  \n",
       "9999   0   0   0   0   0   2  \n",
       "\n",
       "[10000 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('data/forest_dataset.csv')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6401742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac6449",
   "metadata": {},
   "source": [
    "Выделим значения метки класса в переменную `labels`, признаковые описания - в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в numpy-формат с помощью метода `.values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1858e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_data[all_data.columns[-1]].values\n",
    "feature_matrix = all_data[all_data.columns[:-1]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d62506",
   "metadata": {
    "id": "FukXaH_r8PMQ"
   },
   "source": [
    "### Пара слов о sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a6030",
   "metadata": {
    "id": "k5S_0Lfc8PMR"
   },
   "source": [
    "**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b26d4",
   "metadata": {
    "id": "VhVDEG538PMS"
   },
   "source": [
    "`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a980d",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b023db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n",
    "    feature_matrix, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0a2c0",
   "metadata": {
    "id": "z3fGvPqG8PMc"
   },
   "source": [
    "Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n",
    "\n",
    "В качестве примера модели можно привести классификаторы\n",
    "[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n",
    "[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3dad7",
   "metadata": {
    "id": "IuX8Rc7c8PMd"
   },
   "source": [
    "У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода -- `fit` и `predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73746e",
   "metadata": {
    "id": "ZYokUkxO8PMe"
   },
   "source": [
    "Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n",
    "\n",
    "У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n",
    "\n",
    "Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n",
    "\n",
    "Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02bec0",
   "metadata": {
    "id": "malIDW_P8PMp"
   },
   "source": [
    "У моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n",
    "\n",
    "Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n",
    "\n",
    "У логистической регрессии, например, можно поменять параметры `C` и `penalty`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc84eb9",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef04aa",
   "metadata": {},
   "source": [
    "Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n",
    "\n",
    "* число соседей `n_neighbors`\n",
    "* метрика расстояния между объектами `metric`\n",
    "* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ddfa1",
   "metadata": {},
   "source": [
    "**Задание**: Обучите на датасете KNeighborsClassifier из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e6baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "y_pred = clf.predict(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354975b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685d9da",
   "metadata": {},
   "source": [
    "Качество = 0.7365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f724f",
   "metadata": {},
   "source": [
    "__Подберём параметры нашей модели__\n",
    "\n",
    "**Задание**:\n",
    "* Переберите по сетке от 1 до 10 параметр числа соседей\n",
    "\n",
    "* Также вы попробуйте использоввать различные метрики: [`manhattan`, `euclidean`]\n",
    "\n",
    "* Попробуйте использовать различные стратегии вычисления весов: [`uniform`, `distance`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05646974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'metric': ['manhattan', 'euclidean'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_neighbors': [i for i in range(1, 11)],\n",
    "          'weights': ['uniform', 'distance'],\n",
    "          'metric': ['manhattan', 'euclidean']}\n",
    "\n",
    "clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ffc92",
   "metadata": {},
   "source": [
    "Выведем лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4faa21c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790a172",
   "metadata": {},
   "source": [
    "Лучше использовать метрику `manhattan`, количество `n_neighbors` = 4 и тип `weights` - `distance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e241e",
   "metadata": {},
   "source": [
    "**Задание**: используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad762a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_clf = KNeighborsClassifier()\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "pred_prob = clf.predict_proba(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47590b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique, freq = np.unique(test_labels, return_counts=True)\n",
    "freq = list(map(lambda x: x / len(test_labels),freq))\n",
    "\n",
    "pred_freq = pred_prob.mean(axis=0)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n",
    "plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n",
    "plt.ylim(0, 0.54)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f113a",
   "metadata": {},
   "source": [
    "**Задание**: какая прогнозируемая вероятность pred_freq класса под номером 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b35f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05430000000000008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_freq[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
